{"0": {
    "doc": "F.A.Q",
    "title": "F.A.Q",
    "content": "Frequently Asked Questions . ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/FAQ.html#faq",
    "relUrl": "/FAQ.html#faq"
  },"1": {
    "doc": "F.A.Q",
    "title": "Q: I get ‚ÄúEnsure condition failed: InDependenciesCrc.IsValid()‚Äù when caching/uncaching PCGEx nodes!",
    "content": "Yes. It‚Äôs ok, you can ignore these. PCG isn‚Äôt natively architectured to support node that switch between cacheable/not-cacheable, which sometime generates failed checks. It‚Äôs annoying but is harmless. The benefits of switching caching mode outweights the assert in my opinion ‚Äì if that bugs you, don‚Äôt touch to the checkbox, it‚Äôs generally safer not to ship with cached data anyway. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/FAQ.html#q-i-get-ensure-condition-failed-independenciescrcisvalid-when-cachinguncaching-pcgex-nodes",
    "relUrl": "/FAQ.html#q-i-get-ensure-condition-failed-independenciescrcisvalid-when-cachinguncaching-pcgex-nodes"
  },"2": {
    "doc": "F.A.Q",
    "title": "F.A.Q",
    "content": " ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/FAQ.html",
    "relUrl": "/FAQ.html"
  },"3": {
    "doc": "About",
    "title": "About",
    "content": "# I'm Tim! I made this. {: .fs-6 .fw-300 } Follow @Nebukam --- I made **PCGEx** as a way to bring some my personal Houdini toolkit into Unreal, and figured it could be useful to my fellow artists and designers. {: .fs-6 .fw-300 } I love my current workflow & tools when it comes to procedural generation, and often needed ways to generate data & structures to... well, generate *more* data and structures to spawn stuff on. Unreal PCG has powerful tools to generate and work with splines, but unless you're making them by hand, spline are a pain to manipulate and maintain at scale -- that's the main reason why I wanted to have tools to create graphs and pathfind in them. Turns out, it's useful for plenty of other things :) ### Special Thanks Massive kudo to MikeC, who has been an early adopter, and whose feedback and suggestions tremendously helped make PCGEx a better and more useful tool <3 *Also thanks to [Sinbad](https://github.com/sinbad), as I shamelessly pasted some of his C++ formatting and practices for this documentation ^_^* ### Source code **PCGEx** is licensed under MIT : if you want to look at the code, or if you're worried it could hurt your machine, the code is available in full on [github](https://github.com/Nebukam/PCGExtendedToolkit). It does not rely on nor embbed any third party library/dlls. ### Bugs! If you encounter a bug, please fill an issue [here](https://github.com/Nebukam/PCGExtendedToolkit/issues). Please provide as much information as you can (stack traces, node setup, ...). ### Improvement & Feature Requests If you have a feature or improvement requestion, please start a discussion [here](https://github.com/Nebukam/PCGExtendedToolkit/discussions/categories/ideas)! ### Footnotes & Credits - I am *not* affiliated with Unreal! - Photo of Edsger W. Dijkstra from Wikipedia, (c) Hamilton Richards / CC BY-SA 3.0 : [source](https://en.wikipedia.org/wiki/Edsger_W._Dijkstra#/media/File:Edsger_Wybe_Dijkstra.jpg) - Photo of Bertran Raphael from Wikipedia, (c) Blogjack / CC BY-SA 3.0 : [source](https://en.wikipedia.org/wiki/Bertram_Raphael#/media/File:Bert_Raphael_2008.JPG) ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/about/",
    "relUrl": "/about/"
  },"4": {
    "doc": "üùê Write Attributes",
    "title": "üùê Write Attributes",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/conditional-actions/action-write-attributes.html",
    "relUrl": "/doc-misc/conditional-actions/action-write-attributes.html"
  },"5": {
    "doc": "üùê Write Result",
    "title": "üùê Write Result",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/conditional-actions/action-write-result.html",
    "relUrl": "/doc-misc/conditional-actions/action-write-result.html"
  },"6": {
    "doc": "All Nodes",
    "title": "All Nodes",
    "content": "{% include header_card %} # All Nodes --- ## Cluster Nodes {% include card_childs reference=\"Clusters\" tagged='clusters' %} --- ## Edges Nodes {% include card_childs reference=\"Edges\" tagged='edges' %} --- ## Pathfinding Nodes {% include card_childs reference=\"Pathfinding\" tagged='pathfinder' %} --- ## Paths Nodes {% include card_childs reference=\"Paths\" tagged='paths' %} --- ## Misc Nodes {% include card_childs reference=\"Misc\" tagged='misc' %} --- ## Sampling Nodes {% include card_childs reference=\"Sampling\" tagged='sampling' %} --- ## Staging Nodes {% include card_childs reference=\"Staging\" tagged='staging' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/all-nodes.html",
    "relUrl": "/all-nodes.html"
  },"7": {
    "doc": "all-pathfinding-modules",
    "title": "all-pathfinding-modules",
    "content": "{% include card_deep_childs parent=\"Goal Pickers\" %} --- {% include card_deep_childs parent=\"Search\" %} --- {% include card_deep_childs parent=\"Heuristics\" %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/all-pathfinding-modules.html",
    "relUrl": "/doc-pathfinding/all-pathfinding-modules.html"
  },"8": {
    "doc": "üù± Actor Collection",
    "title": "üù± Actor Collection",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------| Entries | Entries are a list of actors (soft) references and their associated shared properties.*You really just need to set the Actor property for it to work.* | Do Not Ignore Invalid Entries | Forces distribution of this to NOT skip over invalid entries.This can be useful to create 'weighted' spaces, and can be overriden on a per-node basis. |: **Advanced** :|| Auto Rebuild Staging | Enabled by default.When enabled, any user-made modification to the asset collection will trigger a rebuilding of the staging data *(saves you a click, in case your forget about it.)* | {% include embed id='settings-col-asset' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-assets/asset-collections/asset-collection-actors.html",
    "relUrl": "/doc-assets/asset-collections/asset-collection-actors.html"
  },"9": {
    "doc": "üù± Mesh Collection",
    "title": "üù± Mesh Collection",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|: **Settings** :|| Entries | Entries are a list of meshes (soft) references descriptor and their associated shared properties.*You really just need to set the Descriptor' StaticMesh property for it to work.* | Do Not Ignore Invalid Entries | Forces distribution of this collection to NOT skip over invalid entries.This can be useful to create 'weighted' spaces, and can be overriden on a per-node basis. |: **Advanced** :|| Auto Rebuild Staging | Enabled by default.When enabled, any user-made modification to the asset collection will trigger a rebuilding of the staging data *(saves you a click, in case your forget about it.)* | {% include embed id='settings-col-asset' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-assets/asset-collections/asset-collection-meshes.html",
    "relUrl": "/doc-assets/asset-collections/asset-collection-meshes.html"
  },"10": {
    "doc": "Asset Collection to Set",
    "title": "Asset Collection to Set",
    "content": "{% include header_card_node %} The **Asset Collection to Set** exists in order to support Attribute-set based workflows and still be able to rely and re-use {% include lk id='Asset Collection' %}s in meaningful ways. {: .fs-5 .fw-400 } It's a very straightfoward node that takes an Asset Collection as input and outputs an attribute set from that. Since an {% include lk id='Asset Collection' %} support the concept of nested collections, **it can also be leveraged as an interesting way to generate random pre-selections of assets!** --- # Properties | Property | Description |:-------------|:------------------| Asset Collection | The {% include lk id='Asset Collection' %} to build an attribute set from. | Sub Collection Handling | Defines how sub-collection entries are handled during the generation process *(more below)* | Allow Duplicates | Whether or not to allow duplicate entries inside the output attribute set.*(Same object path is considered a duplicate)* | Omit Invalid and Empty | Whether or not to strip out invalid or empty entries from the output attribute set.*(invalid or empty entries are null or invalid object paths)* | ### Sub Collection Handling |: Handling ||:-------------|:------------------| Ignore | Skips entry. | Expand | Recursively add sub-collection entries. | Random | Picks a random entry from the sub-collection, recursive until it's a non-collection entry. | Random Weighted | Picks a random weighted entry from the sub-collection, recursive until it's a non-collection entry. | First Item | Picks the first entry from the sub-collection, recursive until it's a non-collection entry. | Last Item | Picks the first entry from the sub-collection, recursive until it's a non-collection entry. | {: .enum } ### Outputs You can choose which property from the Asset Collection to build the attribute set from. |: Output properties ||:-------------|:------------------| Asset Path | *FSoftbjectPath* | Weight | *int32* | Category | *FName* | Extents | *FVector* | BoundsMin | *FVector* | BoundsMax | *FVector* | Nesting Depth | *int32* | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-assets/assets-collection-to-set.html",
    "relUrl": "/doc-assets/assets-collection-to-set.html"
  },"11": {
    "doc": "Asset Staging",
    "title": "Asset Staging",
    "content": "{% include header_card_toc %} The **Asset Staging** exists for many reasons, but primarily to \"pre-spawn\" assets from an {% include lk id='Asset Collection' %}, and modify points according to various rules, in relation to their associated asset. {: .fs-5 .fw-400 } This is especially useful if you want to have pruning control on overlaps, or require very tight placement rules no matter how the assets have been authored (pivot point location etc) --- # Properties | Property | Description |:-------------|:------------------|: **Source** :|| Source | Which type of source to use for the asset collection.Can be either `Asset` for an {% include lk id='Asset Collection' %} picker, or `Attribute Set`, which will reveal a new input pin that accepts an attribute set. | Asset Collection | If `Asset` is selected as a source, this is the {% include lk id='Asset Collection' %} that will be used for staging points. | ### Attribute Set Source When using the `Attribute Set` source, the node will create a temp, internal {% include lk id='Asset Collection' %} from the source attribute set. |: **Attribute Set Details** :|| Asset Path Source Attribute | The name of the attribute within the Attribute Set that contains the entry' **Asset Path**.*`FSoftObjectPath` is preferred, but `FString` and `FName` are supported.* | Weight Source Attribute | The name of the attribute within the Attribute Set that contains the entry' **Weight**.*`int32` is preferred, but `float`, `double` and `int64` are supported.* | Category Source Attribute | The name of the attribute within the Attribute Set that contains the entry' **Category**.*`FName` is preferred, but `FString` is supported.* | > While it's a needed option, keep in mind that using an attribute set prevents access to any asset cached data. > **As such, all assets from the Attribute Set will be first loaded (asynchronously) in memory in order to compute their bounds**; before the node execution can properly start. --- ## Scale to Fit Scale the spawned asset bounds in order to fit within the host point' bounds. | Scale to Fit Mode | Which type of scale-to-fit mode is to be applied. `None` disables this section, `Uniform` applies the same rule to each individual component, while `Individual` lets you pick per-component rules. | Scale to Fit *(value)* | If `Asset` is selected as a source, this is the {% include lk id='Asset Collection' %} that will be used for staging points. | You can use the following rules: |: Scale to Fit ||:-------------|:------------------|: **None** :|| IMG | Disable the scaling rule. |: **Fill** :|| IMG | Scale the asset so it fills the point' bounds. |: **Min** :|| IMG | Scale the asset so it fits snuggly within the minimum point' bounds. |: **Max** :|| IMG | Scale the asset so it fits snuggly within the maximum point' bounds. |: **Average** :|| IMG | Scale the asset so it fits the average of the point' bounds.| {: .enum } --- ## Justification Offset the spawned asset bounds relative to the host point' bounds. Justification is done & tweaked per-component. |: **Per component** :|| From | The location within the **Asset** bounds that will be justified *To* the point' bounds. | To | The location withn the **Point** bounds to which the **Asset** bounds will be justified. |: **Consolidated custom inputs** :|| Custom from Vector Attribute | An `FVector` whose individual component will be used to drive `From` properties set to `Custom`. | Custom to Vector Attribute | An `FVector` whose individual component will be used to drive `To` properties set to `Custom`. | ### From You can use the following rules for `From`: |: Justify From ||:-------------|:------------------|: **Min** :|| IMG | Uses the asset bounds' min as reference point. |: **Center** :|| IMG | Uses the asset bounds' local center as reference point. |: **Max** :|| IMG | Uses the asset bounds' max as reference point.|: **Pivot** :|| IMG | Uses the asset pivot as reference point, ignoring bounds. |: **Custom** :|| IMG | Uses a lerped reference point between the asset bounds' min & max.*Value is expected to be in the range 0-1 but isn't clamped.* | {: .enum } ### To You can use the following rules for `To`: |: Justify To ||:-------------|:------------------|: **Same** :|| IMG | Auto-selects the same justification as `From`, but computed against the point' bounds. |: **Min** :|| IMG | Uses the point bounds' min as reference point. |: **Center** :|| IMG | Uses the point bounds' local center as reference point. |: **Max** :|| IMG | Uses the point bounds' max as reference point. |: **Pivot** :|| IMG | Uses the point bounds' pivot, ignoring bounds. |: **Custom** :|| IMG | Uses a lerped reference point between the asset bounds' min & max.*Value is expected to be in the range 0-1 but isn't clamped.* | {: .enum } -- ## Variations When to apply the asset' variations, if any, as defined in the Source. > At the time of writing, this is not supported for `Attribute Set` source. -- ## Distribution -- ## Output ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-assets/assets-staging.html",
    "relUrl": "/doc-assets/assets-staging.html"
  },"12": {
    "doc": "Inherit Last",
    "title": "Inherit Last",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Blending Settings | See{% include lk id='Blending' a='#common-properties' %} *(Common properties)* | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-subdivide/blending-inherit-end.html",
    "relUrl": "/doc-paths/paths-subdivide/blending-inherit-end.html"
  },"13": {
    "doc": "Inherit First",
    "title": "Inherit First",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Blending Settings | See{% include lk id='Blending' a='#common-properties' %} *(Common properties)* | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-subdivide/blending-inherit-start.html",
    "relUrl": "/doc-paths/paths-subdivide/blending-inherit-start.html"
  },"14": {
    "doc": "Interpolate",
    "title": "Interpolate",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Blending Over | Defines the method used to compute the alpha value for the interpolation. | Blending Settings | See{% include lk id='Blending' a='#common-properties' %} *(Common properties)* | ## Blend Over Methods - [Distance](#distance) - [Count](#count) - [Fixed](#fixed) ### Distance {% include img a='details/modules/blendover-distance.png' %} `Distance` will first calculate the total distance covered by the subpoints (*from current to next*), and compute their individual lerp as `Local Distance / Total Distance`. **This usually gives more better-looking results if the distance between points is irregular;** but the difference in values between a point and the next can either be brutal or negligible. *If points are equally spaced, it will look very similar to `Point Count`.* ### Count {% include img a='details/modules/blendover-index.png' %} `Point Count` uses the current point index, and compute their individual lerp as `Current Index / Total Point Count`. **Using this method is equivalent of using a fixed blending step between each point.** *If points are irregularly spaced, it may look a bit random.* ### Fixed Uses a unique fixed lerp value for each point. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-subdivide/blending-interpolate.html",
    "relUrl": "/doc-paths/paths-subdivide/blending-interpolate.html"
  },"15": {
    "doc": "Bounds to Points",
    "title": "Bounds to Points",
    "content": "{% include header_card_node %} # Properties > WIP {: .warning-hl } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-transforms/bounds-to-points.html",
    "relUrl": "/doc-transforms/bounds-to-points.html"
  },"16": {
    "doc": "Break to Paths",
    "title": "Break to Paths",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-break-to-paths.html",
    "relUrl": "/doc-clusters/clusters-break-to-paths.html"
  },"17": {
    "doc": "Connect",
    "title": "Connect",
    "content": "{% include header_card_node %} {% include img a='details/details-bridge-clusters.png' %} # Properties | Property | Description |:-------------|:------------------| Bridge Method | The method that will be used to identify and create bridges between clusters.| > Note that no matter what method is selected, **a bridge will always connect the two closest points between two clusters.** The chosen method only drives which cluster is connected to which other cluster. {: .comment } --- ## Bridge Methods | Method | Description |:-------------|:------------------|**Delaunay**|| {% include img a='docs/bridge/method-delaunay.png' %} | When using this method, each cluster is abstracted into a single bounding box that encapsulates all its vertices. A 3D Delaunay is generated using each bounding box center as an input, and the resulting delaunay edges are used as bridges.|**Least Edges**|| {% include img a='docs/bridge/method-least.png' %} | When using this method, the algorithm will generate the least possible amount of bridge in order to connect all the clusters together.*Careful because it can easily look like a minimum spanning tree, but it's not.*|**Most Edges**|| {% include img a='docs/bridge/method-most.png' %} | When using this method, the algorithm will create a bridge from each cluster to every other cluster.| {% include embed id='settings-performance' %} --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-connect.html",
    "relUrl": "/doc-clusters/clusters-connect.html"
  },"18": {
    "doc": "Copy Cluster to Points",
    "title": "Copy Cluster to Points",
    "content": "> DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-copy-to-points.html",
    "relUrl": "/doc-clusters/clusters-copy-to-points.html"
  },"19": {
    "doc": "Fuse Clusters",
    "title": "Fuse Clusters",
    "content": "{% include header_card_node %} # Properties > Current implementation is **WIP**: not all attributes from the inputs are not forwarded to the output cluster. {: .error } --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-fuse-cluster.html",
    "relUrl": "/doc-clusters/clusters-fuse-cluster.html"
  },"20": {
    "doc": "Make Unique",
    "title": "Make Unique",
    "content": "{% include header_card_node %} *This node has no specific properties.* > This node creates a duplicate of the input data with new unique cluster tags. {: .infos-hl } This node primarily exists to allow certain advanced operations such as copying an existing cluster configuration, modify it and then fuse it with the original one. --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-make-unique.html",
    "relUrl": "/doc-clusters/clusters-make-unique.html"
  },"21": {
    "doc": "Mesh to Clusters",
    "title": "Mesh to Clusters",
    "content": "> DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-mesh-to-clusters.html",
    "relUrl": "/doc-clusters/clusters-mesh-to-clusters.html"
  },"22": {
    "doc": "Pack Clusters",
    "title": "Pack Clusters",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-pack-clusters.html",
    "relUrl": "/doc-clusters/clusters-pack-clusters.html"
  },"23": {
    "doc": "Partition Vertices",
    "title": "Partition Vertices",
    "content": "{% include header_card_node %} *This node has no specific properties.* > Contrary to other edge & cluster processors, this node does **not** produce a sanitized result. > *If the input is unsanitized, you may have unexpected results.* {: .warning } This node primarily exists to allow certain advanced operations such as easily finding individual convex hull of isolated clusters. *This is not a default behavior as doing so slightly increases processing times.* --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-partition-vertices.html",
    "relUrl": "/doc-clusters/clusters-partition-vertices.html"
  },"24": {
    "doc": "Pick Closest Clusters",
    "title": "Pick Closest Clusters",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-pick-closest-clusters.html",
    "relUrl": "/doc-clusters/clusters-pick-closest-clusters.html"
  },"25": {
    "doc": "Prune edges by Length",
    "title": "Prune edges by Length",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Measure | The \"unit\" system to use for measuring edges.*See [Measure](#measure).* | Mean Method | The method used to compute the **mean value** for a cluster.**The mean is what will be used as a reference values to prune edges.***See [Mean Methods](#mean-methods).* | Mode Tolerance | Value used for length equality tolerance.*Only available when using `Mode (Shortest)` or `Mode (Longest)` mean methods.* |**Pruning**|| Prune Below | If enabled, edges with a value **below the mean from the specified threshold** will be pruned. | Prune Above | If enabled, edges with a value **above the mean from the specified threshold** will be pruned. |**Output**|| **Mean** Attribute Name | When enabled, the computed mean value will be written to the specified attribute.*Useful for debugging, and probably has other applications.Note that the mean value is the same for all edges of a given cluster.* | >Keep in mind that calculations are **relative to the mean value.** {: .infos-hl } #### Example {: .no_toc } If using `Relative` measure and `Average` mean method, the mean value will be the *average edge length*. The `Prune Below` value is substracted from that average to find the minimum acceptable length (in relative terms), while the `Prune Above` value is added to that average to find the maximum acceptable length. > In other words, if the average relative mean is `0.5`, using `Prune Below = 0.1` and `Prune Above = 0.1`, edges with a relative length ` 0.6` will be pruned. > *See [Easy pruning](#easy-pruning) if this gives you headaches.* ### Measure | Method | Description |:-------------|:------------------| **Relative** | When using `Relative` measure, edge lengths are pre-processed in order to find the min/max values, in order for the other calculation to work from **normalized** values.This is a bit clumsy to use, but also highly scalable if you're doing sub-graph with no control over the input scale/dimensions. | **Absolute** | This measure uses the **raw** edge length.It's very straighforward to use, but for obvious reason scales poorly; or through PCG overrides by forwarding params from outside. | --- ## Mean Methods The mean method is used to find the reference threshold value that will be used by `Prune Below` and `Prune Above`. Below are an explanation on how each method works. For the example, let's say we're working on a cluster with 10 edges that have the following lengths: ```cpp Absolute lengths = [10, 20, 30, 40, 50, 50, 55, 60, 1200, 500] Relative lengths = [0.0083, 0.016, 0.025, 0.03, 0.041, 0.041, 0.045, 0.05, 1, 0.41] ``` - [Average](#average-arithmetic-mean) - [Median](#median) - [Mode](#mode-shortest-or-longest) - [Central](#central) - [Fixed](#fixed) ### Average (Arithmetic mean) Average mean is, well, the averaged value of all the lengths. ```cpp Absolute Average Mean = 201.5 Relative Average Mean = 0.125 ``` ### Median Median uses the median value of all the available lengths, sorted. ```cpp Sorted Absolute lengths = [10, 20, 30, 40, 50, 50, 55, 60, 500, 1200] Absolute Median Mean = 50 // [.., 50, 50, ...] Sorted Relative lengths = [0.0083, 0.016, 0.025, 0.03, 0.041, 0.041, 0.045, 0.05, 0.41, 1] Relative Median Mean = 0.041 // [.., 0.041, 0.041, ...] ``` ### Mode (Shortest or Longest) See [Mode (statitics) on Wikipedia](https://en.wikipedia.org/wiki/Mode_(statistics)). If there are concurrent mode values (multiple buckets containing the same amount of values), the selected mode variant allows you to select either the mode with the *shortest* lengths, or the one with the *longest* out of the available conflicting modes. ```cpp Absolute Mode Mean = 50 // [50, 50] is the largest bucket of equal values Absolute Mode Mean = 0.041 // [0.041, 0.041] is the largest bucket of equal values ``` *In this is scenario, there is no conflicting frequencies.* >The `Mode Tolerance` property is used to fill frequency buckets based on equality with already sampled values. ### Central Central uses the middle value between the `shortest` and `longest` lengths as mean. ```cpp Absolute Central Mean = 605 // 10 + (1200-10)/2 Relative Central Mean = 0.504 // 0.0083 + (1-0.0083)/2 ``` ### Fixed Fixed mean is basically **user-defined** mean. This is the way to go if you don't care about statistics or if you have a consistent, metrics-driven setup. > This is the least flexible but most performant approach as there is no need to sample any statistics prior to pruning. --- # Usage ## Easy pruning If you just want to prune edge above or below a certain fixed length -- i.e `any edge longer than 500` or `any edge shorter than 42`, just do the following: ### Prune any edge longer than X {% include img a='docs/prune-edges/above-500.png' %} Measure: `Absolute`, Mean Method: `Fixed`, Mean Value: `500`, Prune Above : `0`. *This basically prune all edges which length is above `500 + 0`.* ### Prune any edge shorter than X {% include img a='docs/prune-edges/below-42.png' %} Measure: `Absolute`, Mean Method: `Fixed`, Mean Value: `42`, Prune Below : `0`. *This basically prune all edges which length is below `42 - 0`.* {% include embed id='settings-cluster-output' %} {% include embed id='settings-performance' %} --- # Inputs & Outputs {% include embed id='inputs-vtx-edges' %} {% include embed id='outputs-vtx-edges' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-prune-by-length.html",
    "relUrl": "/doc-clusters/clusters-prune-by-length.html"
  },"26": {
    "doc": "Sanitize Clusters",
    "title": "Sanitize Clusters",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------| Prune Isolated Points | If enabled, input points that are not part of a valid cluster *(either no edges or pruned cluster)* will be omitted from the `Vtx` output.If disabled, the input points are forwarded as-is in the `Vtx` output (with added attributes). | Edge Position | If enabled, this sets the position of the `Edge` points to a lerp between their `Start` and `End` points.*By default, `Edges` point are placed at the center between their two `Vtx`.*| Min Cluster Size | If enabled, any cluster with less **edges** than specified will be pruned from the output. | Max Cluster Size | If enabled, any cluster with more **edges** than specified will be pruned from the output. | --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-sanitize-clusters.html",
    "relUrl": "/doc-clusters/clusters-sanitize-clusters.html"
  },"27": {
    "doc": "Unpack Clusters",
    "title": "Unpack Clusters",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-unpack-clusters.html",
    "relUrl": "/doc-clusters/clusters-unpack-clusters.html"
  },"28": {
    "doc": "Write Edge Properties",
    "title": "Write Edge Properties",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } {% include img a='details/details-edge-extras.png' %} | Property | Description |:-------------|:------------------|**Blending Settings**| When enabled, the edge will inherit properties and attributes from its `Start` and `End` point.It uses {% include lk id='Interpolate' %} blending under the hood. | **Output** || **Edge Length** Attribute Name | When enabled, the `length` of the edge will be written to the specified attribute.*The length of an edge is the distance between its start and end point.* | > DOC TDB {: .warning } {% include embed id='settings-performance' %} --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/clusters-write-edge-properties.html",
    "relUrl": "/doc-clusters/clusters-write-edge-properties.html"
  },"29": {
    "doc": "Debug",
    "title": "Debug",
    "content": "{% include header_card %} - TOC {:toc} --- ## Visual Debugging PCGEx Debug node draw debug information flagged as `persistent`, and as such needs to be flushed. However, there is currently no way in Unreal to selectively flush or tag debug line -- hence they needs to be flushed before they are redrawn *(Or thousands of thousands of line willl stack and bring the editor to its knees)*. This means you need to use {% include lk id='Flush Debug' %} in your flow before using other PCGEx' debug nodes. {% include img a='docs/debug.png' %} *The Flush Debug is basically there to manage execution order and ensure stuffs aren't flushed from the buffer right after they're drawn. It's non-intrusive, and sometimes needs an update or two to work right.* --- ## Debugging inside subgraphs {% include img a='details/details-pcgex-debug.png' %} **When disabled, the input data of a node becomes a simple passthrough.** The `PCGExDebug` property in the `Debug` details of the node is overridable and basically allows you to remotely disable the PCGEx debug nodes. --- ## Available debug nodes At the time of writing, there are three main debug nodes: 1. {% include lk id='Draw Attributes' %} 1. {% include lk id='Draw Edges' %} `Draw Edges` is specific to Edges & Clusters, however {% include lk id='Draw Attributes' %} is designed to work with any input. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/debug/debug.html",
    "relUrl": "/doc-misc/debug/debug.html"
  },"30": {
    "doc": "Draw Edges",
    "title": "Draw Edges",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Color | Primary debug color | Secondary Color | If enabled, each cluster will have a different color ranging from the primary color to the secondary color, based on the dataset index in the inputs. | Thickness | Line thickness | Depth Priority | Debug draw depth priority. - `-1` : draw on top of everything.- `0` : Regular depth sorting.- `1` : Draw behind everything. | --- # Inputs & Outputs > This nodes forwards its inputs as if it was disabled. ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-draw.html",
    "relUrl": "/doc-clusters/edges-draw.html"
  },"31": {
    "doc": "üùñ Adjacency",
    "title": "üùñ Adjacency",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/flag-nodes/filter-adjacency.html",
    "relUrl": "/doc-clusters/flag-nodes/filter-adjacency.html"
  },"32": {
    "doc": "üùñ Bitmask",
    "title": "üùñ Bitmask",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-bitmask.html",
    "relUrl": "/doc-misc/uber-filter/filter-bitmask.html"
  },"33": {
    "doc": "üùñ Bool",
    "title": "üùñ Bool",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-bool.html",
    "relUrl": "/doc-misc/uber-filter/filter-bool.html"
  },"34": {
    "doc": "üùñ Bounds",
    "title": "üùñ Bounds",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-bounds.html",
    "relUrl": "/doc-misc/uber-filter/filter-bounds.html"
  },"35": {
    "doc": "üùñ Dot Product",
    "title": "üùñ Dot Product",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-dot-compare.html",
    "relUrl": "/doc-misc/uber-filter/filter-dot-compare.html"
  },"36": {
    "doc": "üùñ Edge Direction",
    "title": "üùñ Edge Direction",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/flag-nodes/filter-edge-direction.html",
    "relUrl": "/doc-clusters/flag-nodes/filter-edge-direction.html"
  },"37": {
    "doc": "üùñ Group (AND/OR)",
    "title": "üùñ Group (AND/OR)",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-group.html",
    "relUrl": "/doc-misc/uber-filter/filter-group.html"
  },"38": {
    "doc": "üùñ Mean Value",
    "title": "üùñ Mean Value",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-mean-compare.html",
    "relUrl": "/doc-misc/uber-filter/filter-mean-compare.html"
  },"39": {
    "doc": "üùñ Modulo Comparison",
    "title": "üùñ Modulo Comparison",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-modulo-compare.html",
    "relUrl": "/doc-misc/uber-filter/filter-modulo-compare.html"
  },"40": {
    "doc": "üùñ Neighbors Count",
    "title": "üùñ Neighbors Count",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/flag-nodes/filter-neighbors-count.html",
    "relUrl": "/doc-clusters/flag-nodes/filter-neighbors-count.html"
  },"41": {
    "doc": "üùñ Numeric Comparison",
    "title": "üùñ Numeric Comparison",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-numeric-compare.html",
    "relUrl": "/doc-misc/uber-filter/filter-numeric-compare.html"
  },"42": {
    "doc": "üùñ String Compare",
    "title": "üùñ String Compare",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/filter-string-compare.html",
    "relUrl": "/doc-misc/uber-filter/filter-string-compare.html"
  },"43": {
    "doc": "Node Flag",
    "title": "Node Flag",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/flag-nodes/flag-node.html",
    "relUrl": "/doc-clusters/flag-nodes/flag-node.html"
  },"44": {
    "doc": "Flat Projection",
    "title": "Flat Projection",
    "content": "{% include header_card_node %} # Properties > WIP {: .warning-hl } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-transforms/flat-projection.html",
    "relUrl": "/doc-transforms/flat-projection.html"
  },"45": {
    "doc": "Basics",
    "title": "Basics",
    "content": "{% include header_card %} Throrough this doc, you will find mention of **points**, **Dataset**, **vtx**, **edges**, **clusters**, **paths** and more. While more advanced concepts are expanded on their own page, here are a few basics: ## Points Points are smallest piece of data you work with within PCG. They have a list of **Static properties** such as `$Density`, `$Color`, `$Position`, `$Rotation` etc. While you can change their values, you can't remove any of them from a point. They're its DNA. On top of static properties, point can have **Dynamic attributes**, which are custom, user-defined properties which type, names and value you control. > PCGEx leverages attributes a lot, and doesn't deal too much in properties except for blending. {: .comment } > Some PCGEx nodes uses attributes to store internal data. These are prefixed `PCGEx/`. Try not do modify these unless you know exactly what you're doing -- most of them are more complex data stored as `uint64`. {: .warning } ## Dataset Often *Point* Datasets, they are container for a single type of more atomic data -- i.e, points. Contrary to points that share a common set of static properties, each Dataset can have its own custom list of attributes; with per-point values. Most PCGEx nodes can take multiple *Dataset* as input, and will process them in parallel. Some very specific nodes are processing Dataset against each others, but it's clear when they do so. It's important to understand that most PCGEx nodes will do their biding on individual Datasets, ignoring what's going on with others processed in parallel : things like min/max values for example are computed *per* Dataset, and never against the entierety of the inputs. > As a rule of thumb, PCGEx will always process Dataset in solation of the others, and **output Dataset in the same order as they are in the input**. {: .comment } ## Paths, Vtx and Edges PCGEx uses the terms **Paths**, **Vtx** and **Edges** for some inputs & ouputs. **These are just regular Point Datasets whose name is used to convey certain assumptions**. Those assumptions are covered in more details on specific sections of the doc. Namely {% include lk id='Clusters' %} and {% include lk id='Paths' %} > Keep in mind that these are *just points* and they can be used with any other regular node -- not just PCGEx! {: .infos-hl } ## Clusters Clusters is the word PCGEx uses to mean *Connected pair/groups of points*. Pairs/groups are identified & retrieved through tags at the moment; *that will change in the future for a more robust approach.* While they are still *just points*, make sure to check out the {% include lk id='Clusters' %} specific documentation! > Cluster-related nodes uses tags to store internal data. These are prefixed `PCGEx/`. Try not do modify these unless you know exactly what you're doing. {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-general/general-concepts.html",
    "relUrl": "/doc-general/general-concepts.html"
  },"46": {
    "doc": "Convex Hull 2D",
    "title": "Convex Hull 2D",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Prune Points | If enabled, `Vtx` that aren't part of the hull are pruned from the output. | **Hull** Attribute Name | Name of the attribute to write the \"is on hull\" flag to.*Disabled if points are pruned, since the output in that case will be exclusively hull points.* |**Projection Settings**| Projection settings allow you to control the projection plane used to compute the graph in 2D. See [Projection Settings](#settings-projection)| > Note that the hull is *optimized* and will ignore points that *lie* on the hull but don't mathematically influence it *(i.e collinear/coplanar points)*. {: .warning } {% include embed id='settings-projection' %} --- # Inputs ## In The input points to generate a Convex Hull from. Each input dataset is processed separately and will generate its own hull. --- # Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ## Paths TBD ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/hulls/graphs-convex-hull-2d.html",
    "relUrl": "/doc-clusters/hulls/graphs-convex-hull-2d.html"
  },"47": {
    "doc": "Convex Hull 3D",
    "title": "Convex Hull 3D",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Prune Points | If enabled, `Vtx` that aren't part of the hull are pruned from the output. | **Hull** Attribute Name | Name of the attribute to write the \"is on hull\" flag to.*Disabled if points are pruned, since the output in that case will be exclusively hull points.* | > Note that the hull is *optimized* and will ignore points that *lie* on the hull but don't mathematically influence it *(i.e collinear/coplanar points)*. {: .warning } --- # Inputs ## In The input points to generate a Convex Hull from. Each input dataset is processed separately and will generate its own hull. --- # Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/hulls/graphs-convex-hull-3d.html",
    "relUrl": "/doc-clusters/hulls/graphs-convex-hull-3d.html"
  },"48": {
    "doc": "Delaunay 2D",
    "title": "Delaunay 2D",
    "content": "{% include header_card_node %} # Properties > If you'd like to know more about Delaunay intrinsic properties, check out the [Wikipedia article](https://en.wikipedia.org/wiki/Delaunay_triangulation)! | Property | Description |:-------------|:------------------|**Settings**|| Urquhart | If enabled, outputs the [Urquhart](https://en.wikipedia.org/wiki/Urquhart_graph) graph instead of Delaunay. |**Hull Identification**|| **Hull** Attribute Name | Name of the attribute to write the \"is on hull\" flag to. | Mark Edge on Touch | If enabled, edges that *connects to a hull point without being on the hull themselves* will be considered as \"on hull\". |**Projection Settings**| Projection settings allow you to control the projection plane used to compute the graph in 2D. See [Projection Settings](#settings-projection)| > Note that the hull is *optimized* and will ignore points that *lie* on the hull but don't mathematically influence it *(i.e collinear/coplanar points)*. {: .warning } {% include embed id='settings-projection' %} --- # Inputs ## In The input points to generate a Delaunay triangulation from. Each input dataset is processed separately and will generate its own triangulation. --- # Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/graphs/graphs-delaunay-2d.html",
    "relUrl": "/doc-clusters/graphs/graphs-delaunay-2d.html"
  },"49": {
    "doc": "Delaunay 3D",
    "title": "Delaunay 3D",
    "content": "{% include header_card_node %} # Properties > If you'd like to know more about Delaunay intrinsic properties, check out the [Wikipedia article](https://en.wikipedia.org/wiki/Delaunay_triangulation)! | Property | Description |:-------------|:------------------|**Settings**|| Urquhart | If enabled, outputs the [Urquhart](https://en.wikipedia.org/wiki/Urquhart_graph) graph instead of Delaunay. |**Hull Identification**|| **Hull** Attribute Name | Name of the attribute to write the \"is on hull\" flag to. | Mark Edge on Touch | If enabled, edges that *connects to a hull point without being on the hull themselves* will be considered as \"on hull\". | > Note that the hull is *optimized* and will ignore points that *lie* on the hull but don't mathematically influence it *(i.e collinear/coplanar points)*. {: .warning } --- # Inputs ## In The input points to generate a Delaunay tetrahedralization from. Each input dataset is processed separately and will generate its own tetrahedralization. --- # Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/graphs/graphs-delaunay-3d.html",
    "relUrl": "/doc-clusters/graphs/graphs-delaunay-3d.html"
  },"50": {
    "doc": "Voronoi 2D",
    "title": "Voronoi 2D",
    "content": "{% include header_card_node %} # Properties > If you'd like to know more about Voronoi intrinsic properties, check out the [Wikipedia article](https://en.wikipedia.org/wiki/Voronoi_diagram)! | Property | Description |:-------------|:------------------|**Settings**|| Method | The method used to position Voronoi' sites. See [Method](#method) | Bounds Cutoff | If enabled, voronoi sites outside of the input points' bounds will be pruned. Bounds are expanded by this property.*Activating this will enable graph output settings, as the graph is no longer guaranteed to be complete. See {% include lk id='Working with Clusters' a='#graph-output-settings-' %}.* |**Hull Identification**|| **Hull** Attribute Name | Name of the attribute to write the \"is on hull\" flag to. | Mark Edge on Touch | If enabled, edges that *connects to a hull point without being on the hull themselves* will be considered as \"on hull\". |**Projection Settings**| Projection settings allow you to control the projection plane used to compute the graph in 2D. See [Projection Settings](#settings-projection)| > Note that the hull is *optimized* and will ignore points that *lie* on the hull but don't mathematically influence it *(i.e collinear/coplanar points)*. {: .warning } --- ## Method There are three available methods to drive Voronoi' site position in space. | Method | Description |:-------------|:------------------| Balanced | Uses `Canon` site location when site is within bounds, and fallbacks to `Centroid` otherwise. | Canon | Uses the real, computed voronoi site position.**Sites on the outskirts of the graph usually have extreme deformations.** | Centroid | Uses the delaunay' triangulation centroid instead of the real position.*This is usually good looking, but can lead to overlapping edges.* | {% include embed id='settings-projection' %} --- # Inputs ## In The input points to generate a Voronoi graph from. Each input dataset is processed separately and will generate its own graph. --- # Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/graphs/graphs-voronoi-2d.html",
    "relUrl": "/doc-clusters/graphs/graphs-voronoi-2d.html"
  },"51": {
    "doc": "Voronoi 3D",
    "title": "Voronoi 3D",
    "content": "{% include header_card_node %} # Properties > If you'd like to know more about Voronoi intrinsic properties, check out the [Wikipedia article](https://en.wikipedia.org/wiki/Voronoi_diagram)! | Property | Description |:-------------|:------------------|**Settings**|| Method | The method used to position Voronoi' sites. See [Method](#method) | Bounds Cutoff | If enabled, voronoi sites outside of the input points' bounds will be pruned. Bounds are expanded by this property.*Activating this will enable graph output settings, as the graph is no longer guaranteed to be complete. See {% include lk id='Working with Clusters' a='#graph-output-settings-' %}.* |**Hull Identification**|| **Hull** Attribute Name | Name of the attribute to write the \"is on hull\" flag to. | Mark Edge on Touch | If enabled, edges that *connects to a hull point without being on the hull themselves* will be considered as \"on hull\". | > Note that the hull is *optimized* and will ignore points that *lie* on the hull but don't mathematically influence it *(i.e collinear/coplanar points)*. {: .warning } --- ## Method There are three available methods to drive Voronoi' site position in space. | Method | Description |:-------------|:------------------| Balanced | Uses `Canon` site location when site is within bounds, and fallbacks to `Centroid` otherwise. | Canon | Uses the real, computed voronoi site position.**Sites on the outskirts of the graph usually have extreme deformations.** | Centroid | Uses the delaunay' triangulation centroid instead of the real position.*This is usually good looking, but can lead to overlapping edges.* | --- # Inputs ## In The input points to generate a Voronoi graph from. Each input dataset is processed separately and will generate its own graph. --- # Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/graphs/graphs-voronoi-3d.html",
    "relUrl": "/doc-clusters/graphs/graphs-voronoi-3d.html"
  },"52": {
    "doc": "üù∞ Heuristic Attribute",
    "title": "üù∞ Heuristic Attribute",
    "content": "{% include header_card %} > DOC TDB -- Heuristics underwent a thorough refactor that isn't documented yet. See the example project! {: .warning } Heuristics Attribute allows fine-grained and precise control over pathfinding constraints by leveraging user-defined attributes. {: .fs-5 .fw-400 } >When dealing with modifiers, keep in mind that **lower values are considered better** than higher ones by the {% include lk id='Search' %} algorithms. {: .error } #### Checklist {: .no_toc } - TOC {:toc} --- {% include imgc a='pathfinding/heuristic-modifier-list.png' %} ## Properties | Property | Description |:-------------|:------------------| Reference Weight | The reference weight is used internally by heuristics to \"adapt\" its scale against modifiers. *In other words, if the heuristic module itself was outputing a value like a modifier, this would its `Weight` property.* | **Modifier List** | A list of individual modifiers. Their values are accumulated per `Source`, and the final sum is used by the {% include lk id='Search' %} algorithm. | --- # Individual Modifier {% include imgc a='pathfinding/heuristic-modifier-solo.png' %} ## Properties | Property | Description |:-------------|:------------------| Enabled | If disabled, this modifier will be ignored by the pathfinding process. *This is basically a QoL toggle to facilitate experimentation and better understand the impact of a specific modifier when they start pilling up.* | Source | Source define if the attribute value of the modifier is fetched from the `Vtx` point data, or from the `Edge` point data.*See {% include lk id='Pathfinding' %}.* | **Weight** | The weight of a modifier represent its final maximum value. | Selector | Attribute to read modifier value from. Reads a `double`.*See {% include lk id='Attribute Selectors' %}.* | Local Weight | If enabled, the weight used for the modifier is fetched from a local attribute (same `Source`` as base value), allowing for per-point weight. | **Score Curve** | The score curve is a key control element of the final modifier value. It allows your to fully leverage the range of the input attribute value in any way you see fit.*More infos below.* | ### Weight >Under the hood, the value of a modifier is remapped from its min/max to 0-1. That remapped value is used to sample the (Score Curve)[#score-curve] and *then* that value is multiplied by the weight. >**Depending on the selected Search, this value is post-processed to ensure it is absolute (non-negative)** ### Score Curve üìå The score curve is a key control element of the final modifier value. It allows your to fully leverage the range of the input attribute value in any way you see fit. >The curve is expected to stay normalized in the 0-1 range on the `y` axis, and is sampled in the 0-1 range on the `x` axis. **Just keep in mind the resulting sampled value will be made absolute (non-negative), and is used as a multiplier.** {: .error } --- ## Examples Say we set-up a point attribute modifier using `MyWeightAttribute`, which has raw values ranging from `-50` to `50`, with a **weight** of `100`. 1. Raw values will be remapped to 0-1 2. The curve will be sampled, then multiplied by the **weight**. ### A - Linear {% include imgc a='pathfinding/score-curve-example-a.png' %} This is the default, linear curve. It doesn't modulate weight, so the final weight will closely match the attribute range. | Raw attribute value | ‚Üí Remapped to | ‚Üí Sampled at | ‚Üí Final weight |:-------------|:------------------|:------------------|:------------------| -50 | 0.0 | 0|**0**| -25 | 0.25 | 0.25|**25**| 0 | 0.5 | 0.5 |**50**| 25 | 0.75 | 0.75 |**75**| 50 | 1.0 | 1.0 |**100**| ### B - Expo {% include imgc a='pathfinding/score-curve-example-b.png' %} Exponential curve is very useful to emphasize higher values and \"ignore\" lower ones. *This can be especially useful when the attribute is for example the edge length, the resulting weight would strongly discourage long edges* | Raw attribute value | ‚Üí Remapped to | ‚Üí Sampled at | ‚Üí Final weight |:-------------|:------------------|:------------------|:------------------| -50 | 0.0 |0.0|**0**| -25 | 0.25 |0.01|**1**| 0 | 0.5 |0.05|**5**| 25 | 0.75 |0.25|**25**| 50 | 1.0 |1.0|**100**| ### C - Inverse Expo {% include imgc a='pathfinding/score-curve-example-c.png' %} Inverted curve (exponential or not) curve is very useful to, well, *inverse* the weight. *This is especially handy if you want to discourage smaller values and ignore higher ones.* | Raw attribute value | ‚Üí Remapped to | ‚Üí Sampled at | ‚Üí Final weight |:-------------|:------------------|:------------------|:------------------| -50 | 0.0 |1|**100**| -25 | 0.25 |0.25|**25**| 0 | 0.5 |0.05|**5**| 25 | 0.75 |0.01|**1**| 50 | 1.0 |0|**0**| ### D - Yoyo {% include imgc a='pathfinding/score-curve-example-d.png' %} This is really just here to make a comparison with other more classic approaches. This resulting weight would ignore extreme values inside the range and strongly discourage anything closer to the center. | Raw attribute value | ‚Üí Remapped to | ‚Üí Sampled at | ‚Üí Final weight |:-------------|:------------------|:------------------|:------------------| -50 | 0.0 |0|**0**| -25 | 0.25 |0.5|**50**| 0 | 0.5 |1|**100**| 25 | 0.75 |0.5|**50**| 50 | 1.0 |0|**0**| ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/heuristic-attribute.html",
    "relUrl": "/doc-pathfinding/heuristics/heuristic-attribute.html"
  },"53": {
    "doc": "üù∞ Azimuth",
    "title": "üù∞ Azimuth",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/heuristic-azimuth.html",
    "relUrl": "/doc-pathfinding/heuristics/heuristic-azimuth.html"
  },"54": {
    "doc": "üù∞ Shortest Distance",
    "title": "üù∞ Shortest Distance",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/heuristic-distance.html",
    "relUrl": "/doc-pathfinding/heuristics/heuristic-distance.html"
  },"55": {
    "doc": "üù∞ Inertia",
    "title": "üù∞ Inertia",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/heuristic-inertia.html",
    "relUrl": "/doc-pathfinding/heuristics/heuristic-inertia.html"
  },"56": {
    "doc": "üù∞ Least Nodes",
    "title": "üù∞ Least Nodes",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/heuristic-node-count.html",
    "relUrl": "/doc-pathfinding/heuristics/heuristic-node-count.html"
  },"57": {
    "doc": "üù∞ Steepness",
    "title": "üù∞ Steepness",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/heuristic-steepness.html",
    "relUrl": "/doc-pathfinding/heuristics/heuristic-steepness.html"
  },"58": {
    "doc": "üù∞ Turning",
    "title": "üù∞ Turning",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/heuristic-turning.html",
    "relUrl": "/doc-pathfinding/heuristics/heuristic-turning.html"
  },"59": {
    "doc": "Connect Points",
    "title": "Connect Points",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } --- ## Probes {% include card_childs tagged='probe' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/connect-points/",
    "relUrl": "/doc-clusters/connect-points/"
  },"60": {
    "doc": "‚à∑ General",
    "title": "‚à∑ General",
    "content": "{% include header_card %} >When working with specific nodes, make sure to check out the home of the category they belong to as it often contains important infos pertaining to their family of nodes as a whole! {: .infos-hl } {% include card_childs tagged=\"basics\" wrappercss=\"duo\" %} --- Some topics and their modules are more complex, and have a dedicated section: - {% include lk id='Pathfinding' %} - {% include lk id='Clusters' %} {: .fs-6 .fw-300 } --- ## Modules & Sub-processors Modules and sub-processors are instanced classes used across a variety of nodes. {% include card_childs tagged=\"module\" wrappercss=\"duo\" %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-general/",
    "relUrl": "/doc-general/"
  },"61": {
    "doc": "Refine",
    "title": "Refine",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Refinement | This property lets you select which kind of refinement you want to apply to the input clusters.**Specifics of the instanced module will be available under its inner Settings section.***See {% include lk id='Refining' %}.* | Output Only Edges As Points | If enabled, this node will output edges as raw points, without the usually associated cluster. | ## Sanitization The sanitization property lets you enforce some general conditions within the graph. Note that is applied after the refinement. | Sanitization | Description |:-------------|:------------------| None | No sanitization. | Shortest | If a node has no edge left, restore the shortest one.| Longest | If a node has no edge left, restore the longest one.| > Note that the sanitization options offer no guarantee that the initial interconnectivity will be preserved! {: .warning } --- ## Refining modules {% include card_any tagged=\"edgerefining\" %} {% include embed id='settings-cluster-output' %} {% include embed id='settings-performance' %} --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/",
    "relUrl": "/doc-clusters/edges-refine/"
  },"62": {
    "doc": "Search",
    "title": "Search",
    "content": "{% include header_card %} Search algorithms are at the core of PCGEx Pathfinding nodes & capabilities. They are responsible for traversing individual clusters in search for the ideal path between the seed and goal points. {: .fs-5 .fw-400 } *At the time of writing, there are only two algorithms implemented, **A Start** and **Dijkstra**. The next implementation candidates will be **DFS** and **BFS** as they yield slightly different results, althought less friendly to modifiers.* ## Modules {% include card_childs tagged=\"search\" %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/search/",
    "relUrl": "/doc-pathfinding/search/"
  },"63": {
    "doc": "Clusters",
    "title": "Clusters",
    "content": "{% include header_card %} > This section contains simple cluster generators and utilities. Make sure to check out {% include lk id='Working with Clusters' %} first. > It is tightly related to {% include lk id='Edges' %} and {% include lk id='Pathfinding' %} --- ## Clusters Nodes {% include card_childs tagged='node' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/",
    "relUrl": "/doc-clusters/"
  },"64": {
    "doc": "Sampling",
    "title": "Sampling",
    "content": "{% include header_card %} > This section contains raw data samplers. > *They're mostly helpers/boilerplate code to sample and write data to attribute without providing immediate mean of using of the results.* --- ## Sampling Nodes {% include card_childs tagged='node' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/",
    "relUrl": "/doc-sampling/"
  },"65": {
    "doc": "PCG Extended Toolkit",
    "title": "PCG Extended Toolkit",
    "content": "# PCGEx {% include github.html repo=\"PCGExtendedToolkit\" %} The PCG Extended Toolkit is a free (libre) plugin that extends Unreal Engine' Procedural Content Generation pipeline, with a focus on **building clusters & pathfinding**. {: .fs-6 .fw-300 } ‚ÄÅ {% include link_btn title=\"Installation\" color=\"red\" link=\"installation\" %} {% include link_btn title=\"Guides\" color=\"blue\" link=\"guides\" icon=\"left\" %} --- > **This documentation is still heavily work-in-progress, and matches non-release branch. Sorry >. However, every property already has helpful tooltips in editor ;) {: .error } > **Make sure to check the [Example Project](https://github.com/Nebukam/PCGExExampleProject) on github** {: .infos-hl } --- # All Nodes --- ## Clusters Nodes {% include card_childs reference=\"Clusters\" tagged='clusters' %} --- ## Edges Nodes {% include card_childs reference=\"Edges\" tagged='edges' %} --- ## Pathfinding Nodes {% include card_childs reference=\"Pathfinding\" tagged='pathfinder' %} --- ## Paths Nodes {% include card_childs reference=\"Paths\" tagged='paths' %} --- ## Misc Nodes {% include card_childs reference=\"Misc\" tagged='misc' %} --- ## Sampling Nodes {% include card_childs reference=\"Sampling\" tagged='sampling' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/",
    "relUrl": "/"
  },"66": {
    "doc": "Asset Collection",
    "title": "Asset Collection",
    "content": "{% include header_card_toc %} Asset Collections are basically lists of assets that you can then use inside PCG; that all share some basic properties. They exist in different flavors, for different purposes (i.e actors vs meshes), but their main appeal over *Data Table* or *PCG Data Asset* is **caching** and **nesting**. {: .fs-5 .fw-400 } --- ### Cached bounds data {: .no_toc } Each entry has some basic information cached, amongst which the bounds of the referenced asset. This is especially useful as it allows nodes to access an asset bounds' **without having to load the asset in memory**. It enables nodes like {% include lk id='Asset Staging' %} to do some interesting work on points before spawning anything in the world. --- ### Nested collections {: .no_toc } **Each entry can be another collection.** This is where the Asset Collection shines, because a collection can be weighted like any other entry. PCGEx will recognize sub-collection and will keep on digging in these until an asset is found. This is particulary handy when doing random weighted selection, where you want only a *subset* of items to be associated to a particular weight range, and then have a new random weighted pick from inside that range. *Collections can be nested without limits, offering highly granular control over weighted & random distribution.* --- ### Re-usability & templating {: .no_toc } Since they're regular DataAssets, Asset Collections can easily be extended, re-used, shared amongst different settings & PCG setups. --- ### Convertible {: .no_toc } In order to support any workflow, {% include lk id='Asset Collection to Set' %} makes it easy to convert any PCGEx' Asset Collection to a good ol' attribute set, on the fly. > Note: Collections currently don't properly check for circular dependencies, so be careful or you're in for a ride. {: .warning } --- ## Creating new collections You can create **Asset Collection** just like any other **DataAsset**: {% include img a='guides/data-asset-collection.jpg' %} --- ## Rebuilding staging data \"Staging data\" is basically per-item cached information. It's pretty lightweight and consist mostly of internal stuffs; and more importantly, asset bounds. > Note: Staging data is refreshed & stored whenever an update is made to the collection, *but won't refresh when the referenced assets are updated.* {: .error } As such you will need to trigger a manual refresh from to time. You can do so using the three buttons at the top of any open Asset Collection: | Button | Effect |:-------------|:------------------| {% include kbkey keys=\"Rebuild Staging\" %} | Rebuilds the currently open Asset Collection | {% include kbkey keys=\"Rebuild Staging (Recursive)\" %} | Rebuild the currently open Asset Collection, as well as any sub-collections; recursively. | {% include kbkey keys=\"Rebuild Staging (Project)\" %} | Rebuild ALL the project' Asset Collection.Use carefully as assets needs to be loaded temporarily in memory in order to compute their bounds. | --- ## Available Collections {% include card_childs tagged='assetcollection' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-assets/asset-collections/",
    "relUrl": "/doc-assets/asset-collections/"
  },"67": {
    "doc": "Conditional Actions",
    "title": "Conditional Actions",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } --- ## Available Actions {% include card_childs tagged='action' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/conditional-actions/",
    "relUrl": "/doc-misc/conditional-actions/"
  },"68": {
    "doc": "Paths",
    "title": "Paths",
    "content": "{% include header_card %} This section contains path-like data utilities. ### Paths are just points Like every other PCGEx thing, **Paths** are really just Points Dataset -- however, **Path nodes assume that the input data represent a \"path\", a.k.a an ordered list of point**. Each point represent a \"step\" inside that path, from the first to last point in the Dataset. > Paths nodes accept any inputs, **and do not rely on any custom attributes to work.**. All path nodes have a `Closed Path` checkbox to indicate whether it should process its input as closed or open paths. > At the time of writing, there is no way to handler per-input closed/open state. **Either all inputs are considered closed, or they are not.**. > This will change in the future, and will likely rely on user-defined tags to know whether a path is to be considered closed or not. {: .warning } --- ## Paths Nodes {% include card_childs tagged='node' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/",
    "relUrl": "/doc-paths/"
  },"69": {
    "doc": "Sample Neighbors",
    "title": "Sample Neighbors",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-neighbors/",
    "relUrl": "/doc-sampling/sampling-neighbors/"
  },"70": {
    "doc": "Graphs",
    "title": "Graphs",
    "content": "{% include header_card %} Classic graphs are very basic generators that can turn any random point cloud into a nicely interconnected structure. Delaunay & Voronoi are two of the most popular algorithms to achieve that; as they offer the benefit of interesting & useful properties. > Note that the 3D version of those generators requires the points to NOT be coplanar for the maths to work -- you'll be prompted to use the 2D version otherwise. {: .warning } --- ## Classic Graphs {% include card_childs tagged='node' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/graphs/",
    "relUrl": "/doc-clusters/graphs/"
  },"71": {
    "doc": "Partition by Values",
    "title": "Partition by Values",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Split Output | Whether to output individual partitions or simply write the unique partition `key` to an attribute. | **Rules** | A list of ordered individual rules used for sorting the points.| Key Sum | Outputs the sum of all partition keys to a `int64` attribute.**This value is unlikely to be unique, but can come in handy for filtering purposes.**See [Key Sum](#key-sum) | ### Partition Rule {% include img a='details/details-partition-rule.png' %} | Property | Description |:-------------|:------------------| Enabled | Whether that rule is enabled or not. *Helpful for trial and error without removing the configuration from the array.* | Selector | An attribute or property that will be used for partitioning. See {% include lk id='Attribute Selectors' %}. | Filter Size | The size of the partition in relation the attribute or property uses.*Higher values means fewer larger partitions; smaller values means more smaller partitions.* |**Input pre-processing**|| Upscale | A scale factor to apply to the selected attribute value before partitioning.*This is especially useful when working with smaller range of values like Density.*See [Why upscale?](#why-upscale). | Offset | An offset value added to the selected attribute value before partitioning.**Offset is added to the Upscaled value.***This allow to shift separation 'lines' when using spatial values for partitioning.* |**Partition Key Attribute**|| **Key** Attribute Name | Whether that rule is enabled or not. *Helpful for trial and error without removing the configuration from the array.* | Use Partition Index as Key | Whether to use the partition `Index` as a key *(starting at 0, up to N partitions)* or the default output *(actual under-the-hood value used to distinguish unique buckets)*.See [How partition Index works](#how-partition-index-works). |**Partition Tagging***Only if `Split Output` is enabled*|| Tag Prefix Name | Tag the data with the partition key, using the format `Prefix::PartitionKey` or `Prefix::PartitionIndex` | Tag Use Partition Index as Key | Whether to use the partition `Index` as a key.See [How partition Index works](#how-partition-index-works). | >When selecting a value to compare, keep in mind that it will be broadcasted to a `double` type. This means that if you don't specify which component to use on multi-component type *(`Vectors`, `Transforms`, etc)*, it will default to the first one (`X`). {: .warning } --- ## Why upscale? Under the hood, the `Partition by Values` broadcast and transform the reference values to a `int64` used as a unique ID for individual partition. Because of that, any value in the -1..1 range (such as `Density`, `Steepness` etc) will be rounded to the nearest integer. **Upscaling fixes this problem.** > For example, without upscaling, [`0.1`, `0.25`, `0.01`] will be partitioned as [`0`, `0`, `0`]; so **a unique `0`-id'd partition**. > On the other end, the same set [`0.1`, `0.25`, `0.01`] upscaled by a factor of `100` will be partitioned as [`10`, `25`, `1`]; so **3 separated partitions**. {: .infos-hl } --- ## How partition Index works The for each partition, the corresponding attribute value is basically upscaled, offsetted and rounded down. This operation is repeated for each partition rule, and points are then distributed into buckets which all have the same partition `keys`. You can either output this \"key\" value as-is, or use the partition `index`. **That index correspond to the partition order when all keys are sorted by ascending order.** Using a single partition rule based on `$Position.X`, using a filter size of `10`. *On the left is the detail panel, on the right is a screencap of the value debugger for that rule* #### Raw partition value {% include img a='docs/partition/filtered.png' %} #### Index partition {% include img a='docs/partition/index.png' %} --- ## Key Sum The Key Sum attribute value will be, well, the *sum* of all unique partitions keys. It's useful in very specific scenarios, such as when partitioning based on booleans values, in order to filter partitions. Say you have three separate boolean (or 0-1) attributes, with a partition rule set up for each of these attributes; with `Use Partition Index as Key` enabled. Each partition will either have a `0` or `1` unique key, with a maximum of 9 partitions created (`0 0 0`, `1 0 0`, `0 1 0` etc.). You will only have 4 different `Key Sum`: `0`, `1`, `2` and `3`, which you can use as *sort-of* weak flag system: - `0 0 0` = `0` - `1 0 0` = `1` - `0 1 0` = `1` - `0 0 1` = `1` - `1 1 0` = `2` - `0 1 1` = `2` - `1 0 1` = `2` - `1 1 1` = `3` --- # Inputs ## In A single point dataset. --- # Outputs ## Out Depending on selected properties, can be the same as Inputs with the added metadata, or completely new per-partition datasets (*usually more than what went it*). *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/partition-by-values/",
    "relUrl": "/doc-misc/partition-by-values/"
  },"72": {
    "doc": "Blending Modules",
    "title": "Blending Modules",
    "content": "{% include header_card %} Blending modules are primarily used by nodes like {% include lk id='Subdivide' %}, as well as under the hood of many nodes where only a sub-selection of parameters will be exposed *(as opposed to full module selection)* {: .fs-5 .fw-400 } > Blending operate on *sub-points* groups, not entire groups -- what \"sub-points\" means is up to the node using the blending. > **Hence, \"First\" and \"Last\" refers to the first & last of the sub-points.** {: .infos-hl } #### Checklist {: .no_toc } - TOC {:toc} ## Modules {% include card_childs tagged=\"blending\" %} --- ## Common Properties blending-common-properties {% include img a='docs/blending-common-properties.png' %} | Selector | Data |:-------------|:------------------| Default Blending | Pick the default blending mode for both point properties and attributes | Properties Overrides | Individual overrides for point properties | Attributes Overrides | Individual overrides for attributes | >Disregard which blendmode appears when greyed out, what is selected as `Default Blending` will be used for those. {: .comment } ### Blendmodes | Selector | Data |:-------------|:------------------| None | Keep the first processed value | Weight | Weights all the processed values. **How that weight of each value is calculated depends on the node, module, and Dataset.** *More often than not, it comes down to a basic lerp.* | Average | Average all the processed values | Min | Keep the minimum value (component-wise) encountered during processing | Max | Keep the maximum value (component-wise) encountered during processing | Copy | Overwrites the value with the last processed one | --- {% include img a='details/modules/blendings.png' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/blending-modules/",
    "relUrl": "/doc-misc/blending-modules/"
  },"73": {
    "doc": "Transforms",
    "title": "Transforms",
    "content": "{% include header_card %} This section contains transform utilities. --- ## Transform Nodes {% include card_childs tagged='transform' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-transforms/",
    "relUrl": "/doc-transforms/"
  },"74": {
    "doc": "Sort Points",
    "title": "Sort Points",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Sort Direction | The output sorting direction -- `Ascending` *(small values first)* or `Descending` *(high values first)*. | **Rules** | A list of ordered individual rules used for sorting the points.| ### Rules ordering Rules are compared **in the same order as in the property panel**, starting at index 0. The sorting goes through each rules until it finds a valid comparison (*non-equal values*) -- for each point. ### Sorting Rule {% include img a='details/details-sort-points-rule.png' %} | Property | Description |:-------------|:------------------| Selector | An attribute or property to compare. See {% include lk id='Attribute Selectors' %}. | Tolerance | Equality tolerance used when comparing two values. | Invert Rule | Switches from the default ``. | >When selecting a value to compare, keep in mind that it will be broadcasted to a `double` type. This means that if you don't specify which component to use on multi-component type *(`Vectors`, `Transforms`, etc)*, it will default to the first one (`X`). {: .warning } --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Same as Inputs but re-ordered. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/sort-points/",
    "relUrl": "/doc-misc/sort-points/"
  },"75": {
    "doc": "Subdivide",
    "title": "Subdivide",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Closed Path | If enabled, will process input paths as closed, effectively wrapping last and first point. | Subdivide Method | Method to be used to define how many points are going to be inserted between existing ones.See [Subdivide Method](#subdivide-method) | Distance *or* Count | Based on the method, specifies how many points will be created. | **Blending** | This property lets you select which kind of blending you want to apply to the input paths.*See [Available Blending Modules](#available-blending-modules).*| ## Subdivide Method | Method | Description |:-------------|:------------------| **Distance** | will create a new point every `X` units inside existing segments, as specified in the `Distance` property.*Smaller values will create more points, larger values will create less points.* | **Count** | will create `X` new points for each existing segments, as specified in the `Count` property. | > `Distance` will create more uniform looking subdivisions, while `Count` is more predictable. --- # Modules ## {% include lk id='Blending' %} {% include card_any tagged=\"blending\" %} --- # Inputs ## In Any number of point datasets assumed to be paths. --- # Outputs ## Out Same as Inputs with the added subdivisions points. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-subdivide/",
    "relUrl": "/doc-paths/paths-subdivide/"
  },"76": {
    "doc": "Write Tangents",
    "title": "Write Tangents",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Closed Path | If enabled, will process input paths as closed, effectively wrapping last and first point. | Arrive Name | Attribute to write the `Arrive` tangent to. | Leave Name | Attribute to write the `Leave` tangent to. | **Tangents** | This property lets you select which kind of tangent maths you want to apply to the input paths.*See [Available Tangents Modules](#available-tangents-modules).*| > The name used for `Arrive` & `Leave` should be used as custom tangent attributes when using the `Create Spline` PCG Node. --- ## Tangents modules {% include card_any tagged=\"pathstangents\" %} --- # Inputs ## In Any number of point datasets assumed to be paths. --- # Outputs ## Out Same as Inputs with the added metadata. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-write-tangents/",
    "relUrl": "/doc-paths/paths-write-tangents/"
  },"77": {
    "doc": "üù∞ Heuristics",
    "title": "üù∞ Heuristics",
    "content": "{% include header_card %} Heuristics modules are primarily used by {% include lk id='Pathfinding' %} nodes, such as {% include lk id='Edges Pathfinding' %} and {% include lk id='Plot Edges Pathfinding' %} {: .fs-5 .fw-400 } Heuristics are basically some under-the-hood maths used by {% include lk id='Search' %} Algorithms to gauge whether one path is better than another. Different algorithms use heuristics differently, but their values is computed consistently. ## Modules {% include card_childs tagged=\"heuristics\" %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/heuristics/",
    "relUrl": "/doc-pathfinding/heuristics/"
  },"78": {
    "doc": "Relax",
    "title": "Relax",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Iterations | The number of time to additively apply the relaxing algorithm.Each iteration uses the previous' iteration results. | Influence | Interpolate between the original position and the final, relaxed position.- `1.0` means fully relaxed- `0.0` means the original position is preserved. | Relaxing | This property lets you select which kind of relaxing you want to apply to the input clusters.**Specifics of the instanced module will be available under its inner Settings section.***See {% include lk id='Relaxing' %}.* | {% include embed id='settings-influence' %} --- ## Relaxing modules {% include card_any tagged=\"relax\" %} {% include img_link a='docs/relax/comparison.png' %} {% include embed id='settings-cluster-output' %} {% include embed id='settings-performance' %} --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} --- # Examples ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-relax/",
    "relUrl": "/doc-clusters/edges-relax/"
  },"79": {
    "doc": "Staging",
    "title": "Staging",
    "content": "{% include header_card %} This section contains data asset & staging utilities. Staging nodes rely on {% include lk id='Asset Collection' %} to **associate points & edit them based on asset properties, such as bounding box.** {: .fs-5 .fw-400 } --- ## Staging Nodes {% include card_childs tagged='staging' %} --- ## {% include lk id='Asset Collection' %} --- {% include card_childs reference=\"Asset Collection\" tagged='assetcollection' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-assets/",
    "relUrl": "/doc-assets/"
  },"80": {
    "doc": "Flag Nodes",
    "title": "Flag Nodes",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/flag-nodes/",
    "relUrl": "/doc-clusters/flag-nodes/"
  },"81": {
    "doc": "Hulls",
    "title": "Hulls",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/hulls/",
    "relUrl": "/doc-clusters/hulls/"
  },"82": {
    "doc": "Pathfinding",
    "title": "Pathfinding",
    "content": "{% include header_card %} > Pathfinding modules for {% include lk id='Pathfinding' %} nodes. Key steps include heuristic computation, goal picking, and search algorithms finding the best path based on weighted connections. {% include lk id='üù∞ Heuristics' %} and their weights are key to the operation. *Note: Plot nodes handle point datasets differently, finding a path through each point in order.* --- ## {% include lk id='Pathfinding' %} {% include card_single reference=\"Edges Pathfinding\" %} {% include card_single reference=\"Plot Edges Pathfinding\" %} --- ## How pathfinding works Although details vary a bit depending on the selected {% include lk id='Search' %} algorithm, the basic gist is, for each path & cluster: 1. {% include lk id='Goal Pickers' %} will find a suitable `Seed` and `Goal` point within the cluster. 2. The Search Algorithm will then find the best path that goes from `Seed` to `Goal`, accounting for its internal maths, and using {% include lk id='üù∞ Heuristics' %} as to determine whether one connection is better than another. {% include imgc a='pathfinding/heuristic-score.png' %} >Note: The `Seed` and `Goal` node are picked based on closest distance to input *positions*. {: .comment } Starting from the seed, each \"next step\" is weighted according to the `V` Vertex weight and the `E` Edge weight that connects to it. The search returns the path found **with the lowest possible weight**, or *score*. {% include imgc a='pathfinding/pathing.png' %} While the selected search algorithm is important, {% include lk id='üù∞ Heuristics' %} are more critical to the operation, as user-defined weights can drastically change and shape the path deemed best by the search. >Note: The `Plot` nodes variations don't have a goal picker and instead process each point Dataset as *a list of points to go through from start to finish*. The first point is the initial seed, the last point is the final goal, and then a path is found that goes through each point in-between, in order. {: .comment } {% include imgc a='pathfinding/ploting.png' %} --- ## Pathfinding Nodes {% include card_childs tagged='node' %} --- {% include embed id='all-pathfinding-modules' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/",
    "relUrl": "/doc-pathfinding/"
  },"83": {
    "doc": "Orient",
    "title": "Orient",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Closed Path | If enabled, will process input paths as closed, effectively wrapping last and first point. | **Orientation** | This property lets you select which kind of orientation arithmetics you want to apply to the input paths.*See [Available Orientation Modules](#available-orienting-modules).*| --- ## Orientation modules {% include card_any tagged=\"pathsorient\" %} --- # Inputs ## In Any number of point datasets assumed to be paths. --- # Outputs ## Out Same as Inputs with the transformation applied. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-orient/",
    "relUrl": "/doc-paths/paths-orient/"
  },"84": {
    "doc": "Smooth",
    "title": "Smooth",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Closed Path | If enabled, will process input paths as closed, effectively wrapping last and first point. | Preserve Start | If enabled, the first point will be unaffected by the smoothing*Same as if its local influence was `0`.* | Preserve End | If enabled, the last point will be unaffected by the smoothing*Same as if its local influence was `0`.* | Influence | Global influence.This is used as a value to lerp the smoothed points properties with the unsmoothed one.- `0` = Not smoothed- `1` = Fully smoothed | Local Influence | If enabled, the influence property is applied per-point using the specified attribute from the point being smoothed. | **Smoothing** | This property lets you select which kind of smoothing you want to apply to the input paths.*See [Available Smoothing Modules](#available-smoothing-modules).*| --- ## Smoothing modules {% include card_any tagged=\"pathsmoothing\" %} --- # Inputs ## In Any number of point datasets assumed to be paths. --- # Outputs ## Out Same as Inputs with the transformation applied. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-smooth/",
    "relUrl": "/doc-paths/paths-smooth/"
  },"85": {
    "doc": "Write Vtx Properties",
    "title": "Write Vtx Properties",
    "content": "{% include header_card_node %} > DOC TDB {: .warning } --- ## Extra Modules {% include card_childs tagged='vtx-property' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-write-vtx-properties/",
    "relUrl": "/doc-clusters/edges-write-vtx-properties/"
  },"86": {
    "doc": "Uber Filter",
    "title": "Uber Filter",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } --- ## Available Filters {% include card_childs tagged='filter' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/uber-filter/",
    "relUrl": "/doc-misc/uber-filter/"
  },"87": {
    "doc": "Misc",
    "title": "Misc",
    "content": "{% include header_card %} --- ## Misc Nodes {% include card_childs tagged='node' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/",
    "relUrl": "/doc-misc/"
  },"88": {
    "doc": "Goal Pickers",
    "title": "Goal Pickers",
    "content": "{% include header_card %} Heuristics modules are primarily used by {% include lk id='Pathfinding' %} nodes, such as {% include lk id='Edges Pathfinding' %} and {% include lk id='Plot Edges Pathfinding' %} {: .fs-5 .fw-400 } ## Modules {% include card_childs tagged=\"goalpicker\" %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/goal-pickers/",
    "relUrl": "/doc-pathfinding/goal-pickers/"
  },"89": {
    "doc": "inputs-vtx-edges",
    "title": "inputs-vtx-edges",
    "content": "## Inputs ### Vtx ### Edges ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/inputs-vtx-edges.html",
    "relUrl": "/settings/inputs-vtx-edges.html"
  },"90": {
    "doc": "‚à∑ Installation",
    "title": "‚à∑ Installation",
    "content": "{% include header_card %} ## Drop-in Package The easiest way to install PCGExtendedToolkit is to download the packaged version of the plugin. However, for the sake of simplicity (and size), a packaged version only exist for the latest *launcher* minor release of the engine, at the time the PCGEx release was published. {% include link_btn title=\"PCGEx for Unreal **5.4** (Package)\" color=\"blue\" link=\"https://github.com/Nebukam/PCGExtendedToolkit/releases/latest/download/PCGExtendedToolkit-5.4.zip\" icon=\"load-arrow\" %} {% include link_btn title=\"PCGEx for Unreal **5.3** (Package)\" color=\"blue\" link=\"https://github.com/Nebukam/PCGExtendedToolkit/releases/latest/download/PCGExtendedToolkit-5.3.zip\" icon=\"load-arrow\" %} Simply download one of the .zip above and put `PCGExtendedToolkit` directly in your `YourProject/Plugins/` folder. {: .fs-5 } > Note that **these packages are created in windows, for windows** -- you can always compile the plugin yourself from the sources if the latest package doesn't work for your version of the editor. {: .comment } --- ## Build from Source ‚ÄÅ {% include link_btn title=\"Github\" color=\"red\" link=\"https://github.com/Nebukam/PCGExtendedToolkit\" icon=\"load-arrow\" %} > If building from source, make sure your project & computer is set-up for C++ dev. [See Epic Documentation on the topic](https://docs.unrealengine.com/4.26/en-US/ProductionPipelines/DevelopmentSetup/VisualStudioSetup/). {: .comment } --- ## Cloning & Build using Git The best way is to clone the repository to a submodule; that way you can contribute pull requests if you want. ```console > cd YourProject > git submodule add https://github.com/Nebukam/PCGExtendedToolkit Plugins/PCGExtendedToolkit > git add ../.gitmodules > git commit ``` --- ## Install from the Source' ZIP ‚ÄÅ {% include link_btn title=\"Download from Github (.zip)\" color=\"white\" link=\"https://github.com/Nebukam/PCGExtendedToolkit/zipball/main\" icon=\"load-arrow\" %} Alternatively you can download the ZIP of this repo and place it in `YourProject/Plugins/PCGExtendedToolkit` --- ## Finding Nodes Once the plugin is installed and compiled, nodes are available in any PCG Graph along with vanilla nodes. You can either find them in the explorer on the left, or in the list when right-clicking any empty space in the graph. {: .fs-5 .fw-400 } > All PCGEx nodes are prefixed with `PCGEx |` -- which is a bit annoying at first, but quickly comes in handy to ensure nodes are clearly identifiable. {: .infos-hl } {% include img a='installation/finding-nodes.png' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/installation.html",
    "relUrl": "/installation.html"
  },"91": {
    "doc": "Attribute Remap",
    "title": "Attribute Remap",
    "content": "{% include header_card_node %} > Note that this node **only support attribute and not properties**, *extra selectors* will be ignored. {: .warning } > Additional note: this node works in a component-wise fashion: the remapping will be done individually for each component of the input data. By default the same remapping rule is applied to each component, but you can freely override the behavior per-component. {: .comment } {% include img a='details/details-attribute-remap.png' %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Source Attribute Name | The source attribute to read data from. | Target Attribute Name | The target attribute to write data to.*Can be the same as `Source`.*|**Remap (Default)**||**Input Clamp Settings**|| Clamp Min | If enabled, input data smaller than the specified value will be clamped. | Clamp Max | If enabled, input data greater than the specified value will be clamped. |**Remap Settings**|| In Min | If enabled, lets you input the `In Min` value manually for the remapping.**If left disabled, this value will be the minimum found in the input dataset.** | In Max | If enabled, lets you input the `In Max` value manually for the remapping.**If left disabled, this value will be the maximum found in the input dataset.** | Scale | A scale factor applied to the output, remapped value.*See [Remap Curve & Scale](#remap-curve--scale).* | Range Method | Basically lets you choose whether the smallest value should be `0` (Full Range) or the effective `Min` value (Effective range).*See [Range Method](#range-method).* | Remap Curve | The curve that will be sampled for remapping.*See [Remap Curve & Scale](#remap-curve--scale).* |**Output Clamp Settings**| *Same as Input, but applied to the final value before writing it.*|**Remap overrides**|| **Remap (2nd Component)** | Override default settings for the 2nd component (`Y`, `Yaw`, `G`, etc) | **Remap (3rd Component)** | Override default settings for the 3rd component (`Z`, `Pitch`, `B`, etc) | **Remap (4th Component)** | Override default settings for the 4th component (`W`, `A`) | --- ## Remap Curve & Scale The way this node works is by measuring the minimum & maximum attribute value, and remap input values to a `[0..1]` range that is then used to sample the specified `Remap Curve` on the x-axis. The `y` curve value is then multplied by the specified `Scale`. See [Range Method](#range-method) as it drives how values are sampled close to zero! --- ## Range Method {% include img a='docs/relax/range.png' %} > Note that the `Effective Range` method tends to spread/scale the input set of values -- but allows one to leverage the full range of the curve no matter the min/max input values. > **Hence, using `Full Range` with only high (or low) input value will only sample a very narrow portion of the curve.** {: .infos-hl } --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Same as Inputs with the added metadata. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-attribute-remap.html",
    "relUrl": "/doc-misc/misc-attribute-remap.html"
  },"92": {
    "doc": "Bitmask",
    "title": "Bitmask",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-bitmask.html",
    "relUrl": "/doc-misc/misc-bitmask.html"
  },"93": {
    "doc": "Cherry Pick Points",
    "title": "Cherry Pick Points",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-cherry-pick.html",
    "relUrl": "/doc-misc/misc-cherry-pick.html"
  },"94": {
    "doc": "Discard Points by Count",
    "title": "Discard Points by Count",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Min Point Count | If enabled, does not output data with a point count smaller than the specified amount. | Max Point Count | If enabled, does not output data with a point count larger than the specified amount. | --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Inputs that passed the filter. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-discard-points-by-count.html",
    "relUrl": "/doc-misc/misc-discard-points-by-count.html"
  },"95": {
    "doc": "Discard Points by Overlap",
    "title": "Discard Points by Overlap",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-discard-points-by-overlap.html",
    "relUrl": "/doc-misc/misc-discard-points-by-overlap.html"
  },"96": {
    "doc": "Draw Attributes",
    "title": "Draw Attributes",
    "content": "{% include header_card_node %} Each **Draw Attribute** node can display any number of things by fetching values from whatever point data is plugged into the input pin; in the order in which they are set up. --- ## Individual Debug Settings | Property | Description |:-------------|:------------------|**Settings**|| Enabled | Whether these settings are enabled or not. Allows to quickly turn a debug display on/off without deleting the entire entry. | Selector | The attribute or property to draw. | Expressed As | The type of shape/form that will be used to express the selected attribute or property. |**Expression Settings**|| -- | Depending on the selected expression, different settings are available. See[Expressions](#expressions). |**Thickness & Size**|| Thickness | The thickness of the debug line, when drawing a line. | Size | How the `Size` is interpreted depends on the chosen expression. See[Expressions](#expressions). | Local Size Attribute | When enabled, allows you to use a local attribute as a `Size`.*If enabled, the fixed `Size` attribute becomes a multiplier to the local attribute.* |**Color**|| Color | The debug color. | Local Color Attribute | When enabled, allows you to use a local attribute instead of the default `Color` property. | Color Is Linear | Specifies whether the `Local Color` attribute is linear (0-1 based) or hex (0-255).*If disabled, the attribute or property value will be divided by 255 internally.* | Depth Priority | Debug draw depth priority. `-1` : draw on top of everything.`0` : Regular depth sorting.`1` : Draw behind everything. | --- ## Expressions As of writing time, there are a few expression available: - [Direction](#direction) - [Connection (Position)](#connection-position) - [Connection (Point index)](#connection-point-index) - [Point](#point) - [Boolean](#boolean) - ~~[Label](#label)~~ --- ### Direction {% include img a='docs/draw-attributes/direction.png' %} |**Extra Properties**||:-------------|:------------------| Normalize Before Sizing | If enabled, the incoming vector will be normalized before it is resized and drawn. | --- ### Connection (Position) {% include img a='docs/draw-attributes/connect.png' %} Draws a line between the current point' location and the selected attribute or property as a world space position. |**Extra Properties**||:-------------|:------------------| As an offset | If enabled, the incoming vector will be used as an offset from the current point location. | --- ### Connection (Point Index) {% include img a='docs/draw-attributes/connect-index.png' %} Draws a line between the current point' location and another point within the same group as a world space position. The selected attribute or property is used as the index for the point to use as target position. |**Extra Properties**||:-------------|:------------------| As an offset | If enabled, the incoming vector will be used as an offset from the current point location. | > Note: this is a legacy tool for drawing edges, if using clusters, use {% include lk id='Draw Edges' %} instead. {: .comment } --- ### Point {% include img a='docs/draw-attributes/point.png' %} |**Extra Properties**||:-------------|:------------------| As an offset | If enabled, the incoming vector will be used as an offset from the current point location. | --- ### Boolean {% include img a='docs/draw-attributes/bool.png' %} Boolean is similar to Point, except it is drawn at the point' location in space. The debug color is selected based on the input value: **If the value is ` 0`. | --- ### ~~Label~~ >Label is currently not working as expected, despite using engine APIs and not throwing any error when used. --- # Inputs & Outputs > This nodes forwards its inputs as if it was disabled. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/debug/misc-draw-attributes.html",
    "relUrl": "/doc-misc/debug/misc-draw-attributes.html"
  },"97": {
    "doc": "Flush Debug",
    "title": "Flush Debug",
    "content": "{% include header_card %} See {% include lk id='Debug' %} --- # Inputs & Outputs Anything. This node forwards out whatever goes in. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/debug/misc-flush-debug.html",
    "relUrl": "/doc-misc/debug/misc-flush-debug.html"
  },"98": {
    "doc": "Fuse Points",
    "title": "Fuse Points",
    "content": "{% include header_card_node %} {% include img a='docs/fuse/image.png' %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Component Wise Radius | Whether to use a component-wise radius or a spherical one.When component-wise is enabled, distance is checked individually on `X`, `Y` and `Z` axis in world-space. | Radius | Radius within which multiple points are to be fused into a single one. | Preserve Order | If enabled, fused points will be sorted to maintain their original order. |**Blending Settings**| Control how removed points' properties and attributes are blended into the point they are fused to.See {% include lk id='Blending' %}| --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out A processed point dataset for each input dataset. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-fuse-points.html",
    "relUrl": "/doc-misc/misc-fuse-points.html"
  },"99": {
    "doc": "2D Lloyd Relaxation",
    "title": "2D Lloyd Relaxation",
    "content": "{% include header_card_node %} See [Lloyd Relaxation](https://en.wikipedia.org/wiki/Lloyd%27s_algorithm) on Wikipedia. # Properties | Property | Description |:-------------|:------------------|**Settings**|| Output Normalized Index | If enabled, the index will be written as a `double` *(instead of `int32`)*, as a normalized value in the range `[0..1]`. | Output Attribute Name | Name of the attribute to write the point index to. | --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Same as Inputs with the added metadata. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-lloyd-relax-2d.html",
    "relUrl": "/doc-misc/misc-lloyd-relax-2d.html"
  },"100": {
    "doc": "3D Lloyd Relaxation",
    "title": "3D Lloyd Relaxation",
    "content": "{% include header_card_node %} See [Lloyd Relaxation](https://en.wikipedia.org/wiki/Lloyd%27s_algorithm) on Wikipedia. # Properties | Property | Description |:-------------|:------------------|**Settings**|| Output Normalized Index | If enabled, the index will be written as a `double` *(instead of `int32`)*, as a normalized value in the range `[0..1]`. | Output Attribute Name | Name of the attribute to write the point index to. | --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Same as Inputs with the added metadata. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-lloyd-relax-3d.html",
    "relUrl": "/doc-misc/misc-lloyd-relax-3d.html"
  },"101": {
    "doc": "Merge Points by Tags",
    "title": "Merge Points by Tags",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-merge-points-by-tags.html",
    "relUrl": "/doc-misc/misc-merge-points-by-tags.html"
  },"102": {
    "doc": "Meta Cleanup",
    "title": "Meta Cleanup",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-meta-cleanup.html",
    "relUrl": "/doc-misc/misc-meta-cleanup.html"
  },"103": {
    "doc": "Meta Filter",
    "title": "Meta Filter",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-meta-filter.html",
    "relUrl": "/doc-misc/misc-meta-filter.html"
  },"104": {
    "doc": "Partition by Values (Static)",
    "title": "Partition by Values (Static)",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Split Output | Whether to output individual partitions or simply write the unique partition `key` to an attribute. | **Rules** | A list of ordered individual rules used for sorting the points.| Key Sum | Outputs the sum of all partition keys to a `int64` attribute.**This value is unlikely to be unique, but can come in handy for filtering purposes.**See [Key Sum](#key-sum) | ### Partition Rule {% include img a='details/details-partition-rule.png' %} | Property | Description |:-------------|:------------------| Enabled | Whether that rule is enabled or not. *Helpful for trial and error without removing the configuration from the array.* | Selector | An attribute or property that will be used for partitioning. See {% include lk id='Attribute Selectors' %}. | Filter Size | The size of the partition in relation the attribute or property uses.*Higher values means fewer larger partitions; smaller values means more smaller partitions.* |**Input pre-processing**|| Upscale | A scale factor to apply to the selected attribute value before partitioning.*This is especially useful when working with smaller range of values like Density.*See [Why upscale?](#why-upscale). | Offset | An offset value added to the selected attribute value before partitioning.**Offset is added to the Upscaled value.***This allow to shift separation 'lines' when using spatial values for partitioning.* |**Partition Key Attribute**|| **Key** Attribute Name | Whether that rule is enabled or not. *Helpful for trial and error without removing the configuration from the array.* | Use Partition Index as Key | Whether to use the partition `Index` as a key *(starting at 0, up to N partitions)* or the default output *(actual under-the-hood value used to distinguish unique buckets)*.See [How partition Index works](#how-partition-index-works). |**Partition Tagging***Only if `Split Output` is enabled*|| Tag Prefix Name | Tag the data with the partition key, using the format `Prefix::PartitionKey` or `Prefix::PartitionIndex` | Tag Use Partition Index as Key | Whether to use the partition `Index` as a key.See [How partition Index works](#how-partition-index-works). | >When selecting a value to compare, keep in mind that it will be broadcasted to a `double` type. This means that if you don't specify which component to use on multi-component type *(`Vectors`, `Transforms`, etc)*, it will default to the first one (`X`). {: .warning } --- ## Why upscale? Under the hood, the `Partition by Values` broadcast and transform the reference values to a `int64` used as a unique ID for individual partition. Because of that, any value in the -1..1 range (such as `Density`, `Steepness` etc) will be rounded to the nearest integer. **Upscaling fixes this problem.** > For example, without upscaling, [`0.1`, `0.25`, `0.01`] will be partitioned as [`0`, `0`, `0`]; so **a unique `0`-id'd partition**. > On the other end, the same set [`0.1`, `0.25`, `0.01`] upscaled by a factor of `100` will be partitioned as [`10`, `25`, `1`]; so **3 separated partitions**. {: .infos-hl } --- ## How partition Index works The for each partition, the corresponding attribute value is basically upscaled, offsetted and rounded down. This operation is repeated for each partition rule, and points are then distributed into buckets which all have the same partition `keys`. You can either output this \"key\" value as-is, or use the partition `index`. **That index correspond to the partition order when all keys are sorted by ascending order.** Using a single partition rule based on `$Position.X`, using a filter size of `10`. *On the left is the detail panel, on the right is a screencap of the value debugger for that rule* #### Raw partition value {% include img a='docs/partition/filtered.png' %} #### Index partition {% include img a='docs/partition/index.png' %} --- ## Key Sum The Key Sum attribute value will be, well, the *sum* of all unique partitions keys. It's useful in very specific scenarios, such as when partitioning based on booleans values, in order to filter partitions. Say you have three separate boolean (or 0-1) attributes, with a partition rule set up for each of these attributes; with `Use Partition Index as Key` enabled. Each partition will either have a `0` or `1` unique key, with a maximum of 9 partitions created (`0 0 0`, `1 0 0`, `0 1 0` etc.). You will only have 4 different `Key Sum`: `0`, `1`, `2` and `3`, which you can use as *sort-of* weak flag system: - `0 0 0` = `0` - `1 0 0` = `1` - `0 1 0` = `1` - `0 0 1` = `1` - `1 1 0` = `2` - `0 1 1` = `2` - `1 0 1` = `2` - `1 1 1` = `3` --- # Inputs ## In A single point dataset. --- # Outputs ## Out Depending on selected properties, can be the same as Inputs with the added metadata, or completely new per-partition datasets (*usually more than what went it*). *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/partition-by-values/misc-partition-by-values-static.html",
    "relUrl": "/doc-misc/partition-by-values/misc-partition-by-values-static.html"
  },"105": {
    "doc": "Points to Bounds",
    "title": "Points to Bounds",
    "content": "{% include header_card_node %} # Properties **Points to bound** has no dedicated properties and is pretty straighforward to use. It embeds a data blender module, which you can read more about in the specific {% include lk id='Blending' %} section. --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out As many outputs as there are inputs. Each output contains a single point representing the bounds of the corresponding input dataset. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-points-to-bounds.html",
    "relUrl": "/doc-misc/misc-points-to-bounds.html"
  },"106": {
    "doc": "Refresh Seed",
    "title": "Refresh Seed",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Base | A value added to the seed calculation to offset the output value. | --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Same as Inputs with the refreshed seed value. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-refresh-seed.html",
    "relUrl": "/doc-misc/misc-refresh-seed.html"
  },"107": {
    "doc": "Reverse Points Order",
    "title": "Reverse Points Order",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-reverse-point-order.html",
    "relUrl": "/doc-misc/misc-reverse-point-order.html"
  },"108": {
    "doc": "Sort Points (Static)",
    "title": "Sort Points (Static)",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Sort Direction | The output sorting direction -- `Ascending` *(small values first)* or `Descending` *(high values first)*. | **Rules** | A list of ordered individual rules used for sorting the points.| ### Rules ordering Rules are compared **in the same order as in the property panel**, starting at index 0. The sorting goes through each rules until it finds a valid comparison (*non-equal values*) -- for each point. ### Sorting Rule {% include img a='details/details-sort-points-rule.png' %} | Property | Description |:-------------|:------------------| Selector | An attribute or property to compare. See {% include lk id='Attribute Selectors' %}. | Tolerance | Equality tolerance used when comparing two values. | Invert Rule | Switches from the default ``. | >When selecting a value to compare, keep in mind that it will be broadcasted to a `double` type. This means that if you don't specify which component to use on multi-component type *(`Vectors`, `Transforms`, etc)*, it will default to the first one (`X`). {: .warning } --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Same as Inputs but re-ordered. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/sort-points/misc-sort-points-static.html",
    "relUrl": "/doc-misc/sort-points/misc-sort-points-static.html"
  },"109": {
    "doc": "Write Index",
    "title": "Write Index",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Output Normalized Index | If enabled, the index will be written as a `double` *(instead of `int32`)*, as a normalized value in the range `[0..1]`. | Output Attribute Name | Name of the attribute to write the point index to. | --- # Inputs ## In Any number of point datasets. --- # Outputs ## Out Same as Inputs with the added metadata. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/misc-write-index.html",
    "relUrl": "/doc-misc/misc-write-index.html"
  },"110": {
    "doc": "Move Pivot",
    "title": "Move Pivot",
    "content": "{% include header_card_node %} # Properties > WIP {: .warning-hl } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-transforms/move-pivot.html",
    "relUrl": "/doc-transforms/move-pivot.html"
  },"111": {
    "doc": "üù¢ Neighbors Attributes",
    "title": "üù¢ Neighbors Attributes",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-neighbors/neighbor-sample-attributes.html",
    "relUrl": "/doc-sampling/sampling-neighbors/neighbor-sample-attributes.html"
  },"112": {
    "doc": "üù¢ Neighbors Properties",
    "title": "üù¢ Neighbors Properties",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-neighbors/neighbor-sample-propertiers.html",
    "relUrl": "/doc-sampling/sampling-neighbors/neighbor-sample-propertiers.html"
  },"113": {
    "doc": "Average",
    "title": "Average",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Orient Axis | The transform' axis that will be *oriented*. | Up Axis | The Up axis used for the orientation maths. | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-orient/orient-average.html",
    "relUrl": "/doc-paths/paths-orient/orient-average.html"
  },"114": {
    "doc": "LookAt",
    "title": "LookAt",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| LookAt | Select what the point should look at.*See [LookAt Target](#lookat-target).*| Look at Selector | The attribute to fetch as a LookAt target if `LookAt == Attribute`.| Attribute as Offset | If enabled, the attribute specified above will be used as a translation offset from the point location, as opposed to a world space position. |**Orientation**|| Orient Axis | The transform' axis that will be *oriented*. | Up Axis | The Up axis used for the orientation maths. | ## LookAt Target There are three possibilities: - Look At Next : orientation will be computed so the point is oriented toward its next neighbor. - Look At Previous : orientation will be computed so the point is oriented toward its previous neighbor. - Attribute : orientation will be computed so the point looks at the world space position stored in a local attribute. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-orient/orient-lookat.html",
    "relUrl": "/doc-paths/paths-orient/orient-lookat.html"
  },"115": {
    "doc": "Weighted",
    "title": "Weighted",
    "content": "{% include header_card_node %} Weighted orientation balances the orientation of the point between the previous and next point based on perpendicular distance. {% include img a='docs/orient/weight.png' %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Inverse Weight | Reverse the orientation weight.*Weight to next will be used for previous, and vice-versa.* |**Orienting**|| Orient Axis | The transform' axis that will be *oriented*. | Up Axis | The Up axis used for the orientation maths. | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-orient/orient-weighted.html",
    "relUrl": "/doc-paths/paths-orient/orient-weighted.html"
  },"116": {
    "doc": "outputs-vtx-edges",
    "title": "outputs-vtx-edges",
    "content": "## Outputs ### Vtx ### Edges ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/outputs-vtx-edges.html",
    "relUrl": "/settings/outputs-vtx-edges.html"
  },"117": {
    "doc": "üùó Partition Rule",
    "title": "üùó Partition Rule",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/partition-by-values/partition-rule.html",
    "relUrl": "/doc-misc/partition-by-values/partition-rule.html"
  },"118": {
    "doc": "Plot Edges Pathfinding",
    "title": "Plot Edges Pathfinding",
    "content": "{% include header_card_node %} > DOC TDB -- Heuristics underwent a thorough refactor that isn't documented yet. Each heuristic has its own node and they can be combined into the heuristic input of the pathfinding node. See the example project! {: .warning } {% include img a='details/details-pathfinding-edges-plot.png' %} | Property | Description |:-------------|:------------------|**Settings**|| Add Seed to Path | Prepends the *seed position* at the beginning of the output path.*This will create a point with the position of the seed.* | Add Goal to Path | Appends the *goal position* at the end of the output path.*This will create a point with the position of the goal.* | Add Plot Points to Path | Include plot points positions as part of the output path. |**Modules**||**Search Algorithm**| The search algorithm that will be used to solve pathfinding.*Each module has individual settings and documentation -- See [Available Search Algorithms](#available-search-modules).* |**Heuristics**| The base heuristics module that will be used during pathfinding.*Each module has individual settings and documentation -- See [Available Heuristics](#available-heuristics-modules).* |**Heuristics Modifiers**| This property group is available no matter what **Heuristics** have been picked.*See {% include lk id='üù∞ Heuristic Attribute' %}.*| {% include embed id='settings-statistics' %} |**Extra Weighting**||Weight up Visited| If enabled, points and edges will accumulate additional weight are paths are found.This allows you to make \"already in use\" points & edges either more or less desirable for the next internal execution.*Note that accumulated weight is consolidated between each plot points, as opposed to between each plotted path.* |Visited Points Weight Factor| The weight to add to points that have been visited. This is a multiplier of the Heuristic' Modifiers `Reference Weight`.*The weight is added each time a point is used.*|Visited Edges Weight Factor| The weight to add to edges that have been visited. This is a multiplier of the Heuristic' Modifiers `Reference Weight`.*The weight is added each time an edge is used.*|Global Visited Weight| If enabled, additive weight will be shared across the different plotted path. | > **Important note on weighting up visited `Vtx` and `Edges`:** > - The weight is only computed for the pathfinding node and isn't carried over or cached. > - Enabling `Global Visited Weight` breaks parallelism. Tasks are still ran asynchronously, but each path must wait for the previous one to be computed. Impact is usually negligible, but if you have *lots* of paths, it may take noticeably more time to process. --- # Modules ## Available {% include lk id='Search' %} modules {% include card_any tagged=\"search\" %} --- ## Available {% include lk id='üù∞ Heuristics' %} modules {% include card_any tagged=\"heuristics\" %} --- # Inputs ## Plots The plot input supports an unlimited amount of points dataset. Each Plot dataset is interpreted as a list of point that must be connected by a single path, in order, then merged into a single consolidated path. --- # Outputs ## Paths A point dataset for each path generated. Points in the dataset are ordered linearily from start to end. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/pathfinding-edges-plot.html",
    "relUrl": "/doc-pathfinding/pathfinding-edges-plot.html"
  },"119": {
    "doc": "Edges Pathfinding",
    "title": "Edges Pathfinding",
    "content": "{% include header_card_node %} > DOC TDB -- Heuristics underwent a thorough refactor that isn't documented yet. Each heuristic has its own node and they can be combined into the heuristic input of the pathfinding node. See the example project! {: .warning } {% include img a='details/details-pathfinding-edges.png' %} | Property | Description |:-------------|:------------------|**Goal Picker**| The module that will be used to interpret and manipulate goals and seeds inputs.*Each module has individual settings and documentation -- See [Available Goal Pickers](#available-goal-pickers-modules).*|**Settings**|| Add Seed to Path | Prepends the *seed position* at the beginning of the output path.*This will create a point with the position of the seed.* | Add Goal to Path | Appends the *goal position* at the end of the output path.*This will create a point with the position of the goal.* |**Modules**||**Search Algorithm**| The search algorithm that will be used to solve pathfinding.*Each module has individual settings and documentation -- See [Available Search Algorithms](#available-search-modules).* |**Heuristics**| The base heuristics module that will be used during pathfinding.*Each module has individual settings and documentation -- See [Available Heuristics](#available-heuristics-modules).* |**Heuristics Modifiers**| This property group is available no matter what **Heuristics** have been picked.*See {% include lk id='üù∞ Heuristic Attribute' %}.*| {% include embed id='settings-statistics' %} |**Extra Weighting**||Weight up Visited| If enabled, points and edges will accumulate additional weight are paths are found.This allows you to make \"already in use\" points & edges either more or less desirable for the next internal execution. |Visited Points Weight Factor| The weight to add to points that have been visited. This is a multiplier of the Heuristic' Modifiers `Reference Weight`.*The weight is added each time a point is used.*|Visited Edges Weight Factor| The weight to add to edges that have been visited. This is a multiplier of the Heuristic' Modifiers `Reference Weight`.*The weight is added each time an edge is used.*| > **Important note on weighting up visited `Vtx` and `Edges`:** > - The weight is only computed for the pathfinding node and isn't carried over or cached. > - Enabling this feature breaks parallelism. Tasks are still ran asynchronously, but each path must wait for the previous one to be computed. Impact is usually negligible, but if you have *lots* of paths, it may take noticeably more time to process. --- # Modules ## Available {% include lk id='Goal Pickers' %} modules {% include card_any tagged=\"goalpicker\" %} --- ## Available {% include lk id='Search' %} modules {% include card_any tagged=\"search\" %} --- ## Available {% include lk id='üù∞ Heuristics' %} modules {% include card_any tagged=\"heuristics\" %} --- # Inputs ## Seeds & Goals Each of these input data will be forwarded to the selected `Goal Picker`. --- # Outputs ## Paths A point dataset for each path generated. Points in the dataset are ordered linearily from start to end. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/pathfinding-edges.html",
    "relUrl": "/doc-pathfinding/pathfinding-edges.html"
  },"120": {
    "doc": "Find Contours",
    "title": "Find Contours",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } {% include embed id='settings-projection' %} {% include embed id='settings-performance' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/pathfinding-find-contours.html",
    "relUrl": "/doc-pathfinding/pathfinding-find-contours.html"
  },"121": {
    "doc": "Plot Navmesh",
    "title": "Plot Navmesh",
    "content": "{% include header_card_node %} >Important: Currently, the navigation data used by the node is the one returned by `GetDefaultNavDataInstance()`; **hence it requires a navmesh to be built and loaded at the time of execution.** {: .error } # Properties | Property | Description |:-------------|:------------------|**Settings**|| Add Seed to Path | Prepends the *seed position* at the beginning of the output path.*This will create a point with the position of the seed.* | Add Goal to Path | Appends the *goal position* at the end of the output path.*This will create a point with the position of the goal.* | Add Plot Points to Path | Include plot points positions as part of the output path. | Require Naviguable End Location | Ensures the picked goal is close enough to an naviguable location, otherwise doesn't generate a path. |**Post-processing**|| Fuse Distance | Fuse points in the sampled path that are too close together.*The navigation system may sometimes generate intricate paths which points that are very close to each other, which may or may not be suitable for your usecase. This settings gives you a bit of control over that.*| **Blending** | Controls how data is blended on the path points between the `Seed` and `Goal` point.*See {% include lk id='Blending' %}.*| > Remaining properties are [Unreal' navigation system](https://docs.unrealengine.com/4.27/en-US/InteractiveExperiences/ArtificialIntelligence/NavigationSystem/) query specifics. > **Despite using the right API, they seem to be ignored for the most part, which is something I need to look into.** {: .warning } --- # Inputs ## Plots The plot input supports an unlimited amount of points dataset. Each Plot dataset is interpreted as a list of point that must be connected by a single path, in order, then merged into a single consolidated path. --- # Outputs ## Paths A point dataset for each path generated. Points in the dataset are ordered linearily from start to end. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/pathfinding-navmesh-plot.html",
    "relUrl": "/doc-pathfinding/pathfinding-navmesh-plot.html"
  },"122": {
    "doc": "Navmesh Pathfinding",
    "title": "Navmesh Pathfinding",
    "content": "{% include header_card_node %} >Important: Currently, the navigation data used by the node is the one returned by `GetDefaultNavDataInstance()`; **hence it requires a navmesh to be built and loaded at the time of execution.** {: .error } # Properties | Property | Description |:-------------|:------------------|**Settings**|| Add Seed to Path | Prepends the *seed position* at the beginning of the output path.*This will create a point with the position of the seed.* | Add Goal to Path | Appends the *goal position* at the end of the output path.*This will create a point with the position of the goal.* | Require Naviguable End Location | Ensures the picked goal is close enough to an naviguable location, otherwise doesn't generate a path. |**Post-processing**|| Fuse Distance | Fuse points in the sampled path that are too close together.*The navigation system may sometimes generate intricate paths which points that are very close to each other, which may or may not be suitable for your usecase. This settings gives you a bit of control over that.*| **Blending** | Controls how data is blended on the path points between the `Seed` and `Goal` point.*See {% include lk id='Blending' %}.*| > Remaining properties are [Unreal' navigation system](https://docs.unrealengine.com/4.27/en-US/InteractiveExperiences/ArtificialIntelligence/NavigationSystem/) query specifics. > **Despite using the right API, they seem to be ignored for the most part, which is something I need to look into.** {: .warning } --- # Inputs ## Seeds & Goals Each of these input data will be forwarded to the selected `Goal Picker`. --- # Outputs ## Paths A point dataset for each path generated. Points in the dataset are ordered linearily from start to end. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/pathfinding-navmesh.html",
    "relUrl": "/doc-pathfinding/pathfinding-navmesh.html"
  },"123": {
    "doc": "Fuse Collinear",
    "title": "Fuse Collinear",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-bevel.html",
    "relUrl": "/doc-paths/paths-bevel.html"
  },"124": {
    "doc": "Blend",
    "title": "Blend",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Closed Path | If enabled, will process input paths as closed, effectively wrapping last and first point. | **Blending** | This property lets you select which kind of blending you want to apply to the input paths.*See [Available Blending Modules](#available-blending-modules).*| --- # Modules ## Available {% include lk id='Blending' %} Modules {% include card_any tagged=\"blending\" %} --- # Inputs ## In Any number of point datasets assumed to be paths. --- # Outputs ## Out Same as Inputs with the transformation applied. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-blend.html",
    "relUrl": "/doc-paths/paths-blend.html"
  },"125": {
    "doc": "Path √ó Bounds Intersections",
    "title": "Path √ó Bounds Intersections",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-bounds-intersections.html",
    "relUrl": "/doc-paths/paths-bounds-intersections.html"
  },"126": {
    "doc": "Fuse Collinear",
    "title": "Fuse Collinear",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Threshold | Threshold in degree under which the deviation is considered small enough to be collinear. | Fuse Distance | In addition to collinearity, this value allows to fuse points that are close enough. | --- # Inputs ## In Any number of point datasets assumed to be paths. --- # Outputs ## Out A smaller dataset for each input dataset. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-fuse-collinear.html",
    "relUrl": "/doc-paths/paths-fuse-collinear.html"
  },"127": {
    "doc": "Offset",
    "title": "Offset",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-offset.html",
    "relUrl": "/doc-paths/paths-offset.html"
  },"128": {
    "doc": "Path √ó Path Crossings",
    "title": "Path √ó Path Crossings",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-paths-intersections.html",
    "relUrl": "/doc-paths/paths-paths-intersections.html"
  },"129": {
    "doc": "Solidify Path",
    "title": "Solidify Path",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-solidify.html",
    "relUrl": "/doc-paths/paths-solidify.html"
  },"130": {
    "doc": "Path Spline Mesh",
    "title": "Path Spline Mesh",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-spline-mesh.html",
    "relUrl": "/doc-paths/paths-spline-mesh.html"
  },"131": {
    "doc": "Paths to Clusters",
    "title": "Paths to Clusters",
    "content": "{% include header_card_node %} # Properties {% include img a='details/details-paths-to-edges.png' %} | Property | Description |:-------------|:------------------|**Settings**|| Fuse Distance | This define the distance at this the points are considered to be identical. | **Graph Output Settings** | *See {% include lk id='Working with Clusters' a='#graph-output-settings-' %}.* | --- # Inputs ## In Any number of point datasets assumed to be paths. --- # Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %}. *Reminder that empty inputs will be ignored & pruned*. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-to-clusters.html",
    "relUrl": "/doc-paths/paths-to-clusters.html"
  },"132": {
    "doc": "Write Paths Properties",
    "title": "Write Paths Properties",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } | Property | Description |:-------------|:------------------|**Blending Settings**| When enabled, the edge will inherit properties and attributes from its `Start` and `End` point.It uses {% include lk id='Interpolate' %} blending under the hood. | **Output** || **Edge Length** Attribute Name | When enabled, the `length` of the edge will be written to the specified attribute.*The length of an edge is the distance between its start and end point.* | --- # Inputs & Outputs ## Vtx & Edges See {% include lk id='Working with Clusters' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-write-properties.html",
    "relUrl": "/doc-paths/paths-write-properties.html"
  },"133": {
    "doc": "Attribute Selectors",
    "title": "Attribute Selectors",
    "content": "{% include header_card %} A lot of the nodes in PCGEx allow you to select local values or attributes to further tweak and alter the way data is processed. These selectors inherit from native PCG implementation and support both point properties and attribute names as *strings*. {: .fs-5 .fw-400 } {% include img a='docs/pcgex-selector.png' %} > In PCGEx, this is only supported when **reading** from attributes, not writing to them. {: .error} --- ## Component selection PCG natively support suffixing properties & attribute with selectors, such as `.X`, `.Y`, `.Z`; as shown in the debug view. This means you can safely use `$Position.Z` inside an attribute selector in order to select the `Z` value of the `Position` vector. ## Extra Selectors PCGEx expand a tiny bit on that and support additional properties, depending on the underlying data type: > Note that these extra selectors are not case sensitive, and can be used additively: `$Transform.Backward.Length` is a valid selectors. {: .infos } | Selector | Data |:-------------|:------------------|: **Vectors** :|| {% include shortcut keys=\"X\" %} | Uses the X component (`Vector2D`, `Vector`, `Vector4`) | {% include shortcut keys=\"Y\" %} | Uses the Y component (`Vector2D`, `Vector`, `Vector4`) | {% include shortcut keys=\"Z\" %} | Uses the Z component (`Vector`, `Vector4`), fallbacks to `Y`. | {% include shortcut keys=\"W\" %} | Uses the W component (`Vector4`), fallbacks to `Z` | {% include shortcut keys=\"L\" %}, {% include shortcut keys=\"Len\" %}, {% include shortcut keys=\"Length\" %} | Uses the length of the vector |: **Color** :|| {% include shortcut keys=\"R\" %} | Uses the Red value | {% include shortcut keys=\"G\" %} | Uses the Green value | {% include shortcut keys=\"B\" %} | Uses the Blue value | {% include shortcut keys=\"A\" %} | Uses the Alpha value |: **Rotators** :|| {% include shortcut keys=\"R\" %}, {% include shortcut keys=\"RX\" %}, {% include shortcut keys=\"Roll\" %} | Uses the Roll component | {% include shortcut keys=\"Y\" %}, {% include shortcut keys=\"RY\" %}, {% include shortcut keys=\"Yaw\" %} | Uses the Yaw component | {% include shortcut keys=\"P\" %}, {% include shortcut keys=\"RZ\" %}, {% include shortcut keys=\"Pitch\" %} | Uses the Pitch component |: **Quaternions & Transforms** :|| {% include shortcut keys=\"Forward\" %}, {% include shortcut keys=\"Front\" %} | Uses the Forward direction vector | {% include shortcut keys=\"Backward\" %}, {% include shortcut keys=\"Back\" %} | Uses the Backward direction vector | {% include shortcut keys=\"Right\" %} | Uses the Right direction vector | {% include shortcut keys=\"Left\" %} | Uses the Roll direction vector | {% include shortcut keys=\"Up\" %}, {% include shortcut keys=\"Top\" %} | Uses the Up direction vector | {% include shortcut keys=\"Down\" %}, {% include shortcut keys=\"Bottom\" %} | Uses the Down direction vector |: **Transforms** :|| {% include shortcut keys=\"Position\" %}, {% include shortcut keys=\"Pos\" %} | Uses the Position component (`Vector`) | {% include shortcut keys=\"Rotation\" %}, {% include shortcut keys=\"Rot\" %}, {% include shortcut keys=\"Orient\" %} | Uses the Rotation component (`Quaternion`) | {% include shortcut keys=\"Scale\" %} | Uses the Scale component (`Vector`) | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-general/pcgex-attribute-selectors.html",
    "relUrl": "/doc-general/pcgex-attribute-selectors.html"
  },"134": {
    "doc": "PCGEx Nodes",
    "title": "PCGEx Nodes",
    "content": "{% include header_card %} Almost every node in the PCGEx inherit from the same point processor, and as such they have some shared capabilities. {: .fs-5 .fw-400 } PCGEx has a focus on performance and multithreading -- very few nodes are actively computing anything on the main thread, and instead the bulk of the tasks is handled asynchronously; and parallelized whenever possible. This helps keeping the editor *relatively* smooth when performing heavy tasks. {: .fs-5 .fw-400 } #### Common Tweaks {: .no_toc } - TOC {:toc} --- ## Performance {% include img a='docs/pcgex-performance.png' %} ### Do Async Processing Checked by default, you can toggle it off to force synchronous/unparallelized execution of the code. *This is a very legacy option, best leave it to `true`.* ### Chunk Size The chunk size usually represents the number of point a node will process in a single parallel batch. There is no ideal value: too small and you loose the gain of parallelization, too high and you're just hogging thread ressources. **Ultimately, it depends on your specific setup.** A value of `-1` fallbacks to that specific' node default value under the hood. > Unreal PCG plugin recommend a minimum batch size of 256, which is the default value I'm using for most of the nodes. Heavier operations can go as low as 32. ### Cache Result Under the hood, all PCG node come with the ability to cache their result; but the system is designed so it's a compile-time choice, not an editor-time one. I exposed the ability to cache on-demand at the price of some harmless asserts, because once you're done iterating on certain settings, it's worth caching the results. > Be aware that the cache is easily corrupted, and sometime leads to missing points or data; *it's still a small price to pay when you're working iteratively with hundreds of thousands points.* {: .warning } ### Flatten Output Flatten the output of this node. On `5.3` this is an absurdly expensive operation, it's better in `5.4` and should be even faster in `5.5`. Flattening ensure all inherited attribute values are copied to the output, and metadata parenting/inheritance is forfeited in the process. **This is a required step to ensure attribute values are properly saved to PCG Data Assets!** --- ## Input Pruning & De-duping ### De-duplication Datasets are de-duplicated by design in PCGEx -- this means that if you plug the exact same data (as in *same memory pointer*) it will be only processed once -- even if it has different tags. ### Pruning Datasets that are empty and contains no points will be ignored, **and won't be forwarded to the ouput pins**. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-general/pcgex-node.html",
    "relUrl": "/doc-general/pcgex-node.html"
  },"135": {
    "doc": "Goal from Attribute",
    "title": "Goal from Attribute",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Goal Count | Either a `Single Goal` or `Multiple Goals` | Attribute | If `Single Goal` is specified, lets you specify a property or attribute which value will be used as an index within the input goals. | Attributes | If `Multiple Goal` is specified, lets you specify a list of property or attribute which values will be used as an index within the input goals. | Index Safety | Failsafe method if the picked `Goal` index is out of bounds.*See [Index Safety](#index-safety)* | >When using `Multiple Goal`, each seed will attempt to create one connection per entry in the array. >The attribute is fetched on the `Seed` input. {: .infos } {% include embed id='settings-index-safety' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/goal-pickers/picker-attribute.html",
    "relUrl": "/doc-pathfinding/goal-pickers/picker-attribute.html"
  },"136": {
    "doc": "Default",
    "title": "Default",
    "content": "{% include header_card_node %} The default goal picker attempts to match input `Seeds` and `Goals` in a 1:1 fashion. Seed index `0` will be matched to goal index `0`, and so on. # Properties | Property | Description |:-------------|:------------------|**Settings**|| Index Safety | Failsafe method if there are more `Seeds` than there are `Goals`.Note that extra `Goals` are simply ignored.*See [Index Safety](#index-safety)* | {% include embed id='settings-index-safety' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/goal-pickers/picker-default.html",
    "relUrl": "/doc-pathfinding/goal-pickers/picker-default.html"
  },"137": {
    "doc": "Random",
    "title": "Random",
    "content": "{% include header_card_node %} The random goal picker match each `Seed` with one or multiple `Goals`. # Properties | Property | Description |:-------------|:------------------|**Settings**|| Goal Count | How many random goals each seed should connect to.*See [Index Safety](#index-safety)* | Num Goals | When specifying multiple goals, this is the maximum number of goals to connect each seeds to. | Index Safety | Failsafe method if the picked `Goal` index is out of bounds.*See [Index Safety](#index-safety)* | ## Goal Count There are three different methods available: - Single - Random - Fixed ### Single Single will, well, connect to a single random goal. ### Multiple Fixed Random will connect to a fixed number of random goals, specified in `Num Goals`. ### Multiple Random Random will connect to a random number of random goals. The number of connection will be between `0` and `Num Goals` {% include embed id='settings-index-safety' %} ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/goal-pickers/picker-random.html",
    "relUrl": "/doc-pathfinding/goal-pickers/picker-random.html"
  },"138": {
    "doc": "üùÜ Anisotropic",
    "title": "üùÜ Anisotropic",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/connect-points/probe-anisotropic.html",
    "relUrl": "/doc-clusters/connect-points/probe-anisotropic.html"
  },"139": {
    "doc": "üùÜ Closest",
    "title": "üùÜ Closest",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/connect-points/probe-closest.html",
    "relUrl": "/doc-clusters/connect-points/probe-closest.html"
  },"140": {
    "doc": "üùÜ Direction",
    "title": "üùÜ Direction",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/connect-points/probe-direction.html",
    "relUrl": "/doc-clusters/connect-points/probe-direction.html"
  },"141": {
    "doc": "üùÜ Index",
    "title": "üùÜ Index",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/connect-points/probe-index.html",
    "relUrl": "/doc-clusters/connect-points/probe-index.html"
  },"142": {
    "doc": "üùî Keep Highest Score",
    "title": "üùî Keep Highest Score",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-keep-highest-score.html",
    "relUrl": "/doc-clusters/edges-refine/refine-keep-highest-score.html"
  },"143": {
    "doc": "üùî Keep Longest",
    "title": "üùî Keep Longest",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-keep-longest.html",
    "relUrl": "/doc-clusters/edges-refine/refine-keep-longest.html"
  },"144": {
    "doc": "üùî Keep Lowest Score",
    "title": "üùî Keep Lowest Score",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-keep-lowest-score.html",
    "relUrl": "/doc-clusters/edges-refine/refine-keep-lowest-score.html"
  },"145": {
    "doc": "üùî Keep Shortest",
    "title": "üùî Keep Shortest",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-keep-shortest.html",
    "relUrl": "/doc-clusters/edges-refine/refine-keep-shortest.html"
  },"146": {
    "doc": "üùî Minimum Spanning Tree",
    "title": "üùî Minimum Spanning Tree",
    "content": "{% include header_card_node %} This module offers an implementation of [Prim's algorithm](https://en.wikipedia.org/wiki/Prim%27s_algorithm) to find the minimum spanning tree of individual clusters. *By design, the output is guaranteed to be sanitized (e.g, each cluster will retains its existing connectivity properties).* > Under the hood, MST leverages the {% include lk id='Local Distance' %} heuristic module -- enabling full tweaking of what is considered the \"minimum-length\" edge. > *The default settings is the \"canon\" implementation.* {: .infos-hl } {% include img a='docs/refine-mst/image.png' %} {% include img a='docs/refine-mst/details.png' %} | Property | Description |:-------------|:------------------| Heuristics Modifiers | See {% include lk id='üù∞ Heuristic Attribute' %}.| ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-prim-mst.html",
    "relUrl": "/doc-clusters/edges-refine/refine-prim-mst.html"
  },"147": {
    "doc": "üùî Remove Highest Score",
    "title": "üùî Remove Highest Score",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-remove-highest-score.html",
    "relUrl": "/doc-clusters/edges-refine/refine-remove-highest-score.html"
  },"148": {
    "doc": "üùî Remove Longest",
    "title": "üùî Remove Longest",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-remove-longest.html",
    "relUrl": "/doc-clusters/edges-refine/refine-remove-longest.html"
  },"149": {
    "doc": "üùî Remove Lowest Score",
    "title": "üùî Remove Lowest Score",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-remove-lowest-score.html",
    "relUrl": "/doc-clusters/edges-refine/refine-remove-lowest-score.html"
  },"150": {
    "doc": "üùî Remove Overlap",
    "title": "üùî Remove Overlap",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-remove-overlap.html",
    "relUrl": "/doc-clusters/edges-refine/refine-remove-overlap.html"
  },"151": {
    "doc": "üùî Remove Shortest",
    "title": "üùî Remove Shortest",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-refine/refine-remove-shortest.html",
    "relUrl": "/doc-clusters/edges-refine/refine-remove-shortest.html"
  },"152": {
    "doc": "Force Directed",
    "title": "Force Directed",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| TBD | See{% include lk id='Relaxing' a='#common-properties' %} *(Common properties)* | See [Force-directed graph drawing on Wikipedia](https://en.wikipedia.org/wiki/Force-directed_graph_drawing) ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-relax/relax-force-directed.html",
    "relUrl": "/doc-clusters/edges-relax/relax-force-directed.html"
  },"153": {
    "doc": "Laplacian",
    "title": "Laplacian",
    "content": "{% include header_card_node %} *This node has no specific properties.* The basic gist is it iteratively attempts to \"uniformize\" the distance between each nodes based on neighboring edges. See [Laplacian Relaxation on Wikipedia](https://en.wikipedia.org/wiki/Relaxation_(iterative_method)) ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-relax/relax-laplacian.html",
    "relUrl": "/doc-clusters/edges-relax/relax-laplacian.html"
  },"154": {
    "doc": "Sample Nearest Bounds",
    "title": "Sample Nearest Bounds",
    "content": "{% include header_card_node %} # Properties > Each output property is written individually for each point. {: .comment } | Property | Description |:-------------|:------------------|**Sampling**|| Sample Method | Selects the sampling method. See [Sampling Methods](#sampling-methods). | Range Min | Minimum sampling range. | Range Max | Maximum sampling range.**Use `0` to sample all targets.** | > Points that are not within range are ignored. > If no point is found within the specified range, the sampling for that point will be marked as **Usuccessful**. {: .infos } |**Weighting**|| Weight Method | Selects the method used to compute the weight of each target.*See [Weighting](#weighting)*. | Weight Over Distance | Curve used to sample the final weight of each target. |**Outputs**|| **Success** Attribute Name | Writes a boolean attribute to each point specifying whether the sampling has been successful (`true`) or not (`false`). | **Location** Attribute Name | Writes the sampled location, as an `FVector`. | **Look at** Attribute Name | Writes the direction from the point to the sampled location, as an `FVector`. | **Normal** Attribute Name | Writes the normal of the point at the sampled location, as an `FVector`. | Normal Source | Which direction to use as an Up vector for the Normal cross-product maths. | **Distance** Attribute Name | Writes the distance between the point and the sampled location, as a `double`. | **Signed Distance** Attribute Name | Writes the signed distance between the point and the sampled location, as a `double`. | Signed Distance Axis | Which axis to use to determine whether the distance is positive or negative (toward/away).*Currently based on point Transform, this will likely change in the future to an attribute selector.* | **Angle** Attribute Name | Writes the angle between the point and the sampled location, as a `double`. | Angle Axis | Which axis to use to determine the angle sign/range (toward/away) | Angle Range | The output range for the `Angle` value. | > Based on the selected `Sample method`, the output values are a **weighted average** of all the sampled target. > *See [Weighting](#weighting)*. {: .infos-hl } ## Sampling Methods | Method | Description |:-------------|:------------------| Within Range | Samples all points within the specified range. | Closest Target | Sample the single closest target within the specified range. | Farthest Target | Sample the single farthest target within the specified range. | Target Extents | Reverse the sampling mechanisms so points will sample the targets which `Extents` contains them.**At the time of writing, will only check targets which position in world space is within range.***It is recommend to use a max range of `0` with this method.* | {% include embed id='settings-weighting' %} --- ## Weighting {% include img a='docs/relax/range.png' %} > Note that the `Effective Range` method tends to spread/scale the input set of values -- but allows one to leverage the full range of the curve no matter the min/max input values. > **Hence, using `Full Range` with only high (or low) input value will only sample a very narrow portion of the curve.** {: .infos-hl } --- # Inputs ## In Points that will sample the input targets. Each point position in world space will be used as a center for a spherical query of the surrounding target points. ## In Targets A single point group that will be sampled by each point of each dataset pluggued in the `In` pin. --- # Outputs ## Out Same as input, with additional metadata. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-nearest-bounds.html",
    "relUrl": "/doc-sampling/sampling-nearest-bounds.html"
  },"155": {
    "doc": "Sample Nearest Points",
    "title": "Sample Nearest Points",
    "content": "{% include header_card_node %} # Properties > Each output property is written individually for each point. {: .comment } | Property | Description |:-------------|:------------------|**Sampling**|| Sample Method | Selects the sampling method. See [Sampling Methods](#sampling-methods). | Range Min | Minimum sampling range. | Range Max | Maximum sampling range.**Use `0` to sample all targets.** | > Points that are not within range are ignored. > If no point is found within the specified range, the sampling for that point will be marked as **Usuccessful**. {: .infos } |**Weighting**|| Weight Method | Selects the method used to compute the weight of each target.*See [Weighting](#weighting)*. | Weight Over Distance | Curve used to sample the final weight of each target. |**Outputs**|| **Success** Attribute Name | Writes a boolean attribute to each point specifying whether the sampling has been successful (`true`) or not (`false`). | **Location** Attribute Name | Writes the sampled location, as an `FVector`. | **Look at** Attribute Name | Writes the direction from the point to the sampled location, as an `FVector`. | **Normal** Attribute Name | Writes the normal of the point at the sampled location, as an `FVector`. | Normal Source | Which direction to use as an Up vector for the Normal cross-product maths. | **Distance** Attribute Name | Writes the distance between the point and the sampled location, as a `double`. | **Signed Distance** Attribute Name | Writes the signed distance between the point and the sampled location, as a `double`. | Signed Distance Axis | Which axis to use to determine whether the distance is positive or negative (toward/away).*Currently based on point Transform, this will likely change in the future to an attribute selector.* | **Angle** Attribute Name | Writes the angle between the point and the sampled location, as a `double`. | Angle Axis | Which axis to use to determine the angle sign/range (toward/away) | Angle Range | The output range for the `Angle` value. | > Based on the selected `Sample method`, the output values are a **weighted average** of all the sampled target. > *See [Weighting](#weighting)*. {: .infos-hl } ## Sampling Methods | Method | Description |:-------------|:------------------| Within Range | Samples all points within the specified range. | Closest Target | Sample the single closest target within the specified range. | Farthest Target | Sample the single farthest target within the specified range. | Target Extents | Reverse the sampling mechanisms so points will sample the targets which `Extents` contains them.**At the time of writing, will only check targets which position in world space is within range.***It is recommend to use a max range of `0` with this method.* | {% include embed id='settings-weighting' %} --- ## Weighting {% include img a='docs/relax/range.png' %} > Note that the `Effective Range` method tends to spread/scale the input set of values -- but allows one to leverage the full range of the curve no matter the min/max input values. > **Hence, using `Full Range` with only high (or low) input value will only sample a very narrow portion of the curve.** {: .infos-hl } --- # Inputs ## In Points that will sample the input targets. Each point position in world space will be used as a center for a spherical query of the surrounding target points. ## In Targets A single point group that will be sampled by each point of each dataset pluggued in the `In` pin. --- # Outputs ## Out Same as input, with additional metadata. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-nearest-point.html",
    "relUrl": "/doc-sampling/sampling-nearest-point.html"
  },"156": {
    "doc": "Sample Nearest Polyline",
    "title": "Sample Nearest Polyline",
    "content": "{% include header_card_node %} # Properties > Each output property is written individually for each point. > *Each polyline will yield a single sample point: the closest point on the closest segment, within the specified range.* {: .comment } | Property | Description |:-------------|:------------------|**Sampling**|| Sample Method | Selects the sampling method. See [Sampling Methods](#sampling-methods). | Range Min | Minimum sampling range. | Range Max | Maximum sampling range.**Use `0` to sample all segments.** | > Segments that are not within range are ignored. > If no polyline segment is found within the specified range, the sampling for that point will be marked as **Usuccessful**. {: .infos } |**Weighting**|| Weight Method | Selects the method used to compute the weight of each target.*See [Weighting](#weighting)*. | Weight Over Distance | Curve used to sample the final weight of each target. |**Outputs**|| **Success** Attribute Name | Writes a boolean attribute to each point specifying whether the sampling has been successful (`true`) or not (`false`). | **Location** Attribute Name | Writes the location sampled on the polyline, as an `FVector`. | **Look at** Attribute Name | Writes the direction from the point to the location sampled on the polyline, as an `FVector`. | **Normal** Attribute Name | Writes the normal of the point at the location sampled on the polyline, as an `FVector`. | Normal Source | Which direction to use as an Up vector for the Normal cross-product maths. | **Distance** Attribute Name | Writes the distance between the point and the location sampled on the polyline, as a `double`. | **Signed Distance** Attribute Name | Writes the signed distance between the point and the location sampled on the polyline, as a `double`. | Signed Distance Axis | Which axis to use to determine whether the distance is positive or negative (toward/away).*Currently based on point Transform, this will likely change in the future to an attribute selector.* | **Angle** Attribute Name | Writes the angle between the point and the transform sampled on the polyline, as a `double`. | Angle Axis | Which axis to use to determine the angle sign/range (toward/away) | Angle Range | The output range for the `Angle` value. | **Time** Attribute Name | Writes the time (*in `Spline` terms*) of the location sampled on the polyline, as a `double`. | > Based on the selected `Sample method`, the output values are a **weighted average** of all the sampled positions. > *See [Weighting](#weighting)*. {: .infos-hl } ## Sampling Methods | Method | Description |:-------------|:------------------| Within Range | Samples all polylines within the specified range. | Closest Target | Sample the single closest polyline within the specified range. | Farthest Target | Sample the single farthest polyline within the specified range. | Target Extents | Reverse the sampling mechanisms so points will sample the targets which `Extents` contains them.**At the time of writing, will only check targets which position in world space is within range.***It is recommend to use a max range of `0` with this method.* | {% include embed id='settings-weighting' %} --- ## Weighting {% include img a='docs/relax/range.png' %} > Note that the `Effective Range` method tends to spread/scale the input set of values -- but allows one to leverage the full range of the curve no matter the min/max input values. > **Hence, using `Full Range` with only high (or low) input value will only sample a very narrow portion of the curve.** {: .infos-hl } --- # Inputs ## In Points that will sample the input targets. Each point position in world space will be used as a center for a spherical query of the surrounding polylines' segments. ## In Targets Any number of polylines that will be sampled by each point of each dataset pluggued in the `In` pin. > Sampling target location for each target polyline is the **closest point on the closest segment**. {: .error-hl } --- # Outputs ## Out Same as input, with additional metadata. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-nearest-polyline.html",
    "relUrl": "/doc-sampling/sampling-nearest-polyline.html"
  },"157": {
    "doc": "Sample Nearest Surface",
    "title": "Sample Nearest Surface",
    "content": "{% include header_card_node %} > Note that this only works with *simple* collisions -- 'use complex as simple' won't work either. {: .warning-hl } # Properties > Each output property is written individually for each point. {: .comment } | Property | Description |:-------------|:------------------|**Settings**|| Max Distance | Maximum surface search distance. | Local Max Distance | If enabled, will use a local property or attribute as `Max Distance`. |**Outputs**|| **Success** Attribute Name | Writes a boolean attribute to each point specifying whether the sampling has been successful (`true`) or not (`false`).*Sampling is considered unsuccessful if there was no point within the specified range.* | **Location** Attribute Name | Writes the sampled location, as an `FVector`. | **Look at** Attribute Name | Writes the direction from the point to the sampled location, as an `FVector`. | **Normal** Attribute Name | Writes the normal of the surface at the sampled, as an `FVector`. | **Distance** Attribute Name | Writes the distance between the point and the sampled location, as a `double`. |**Collision Settings**|| Max Distance | The maximum distance to search for a collision, from the point location in world space.*In other words, the radius of the query sphere.* | Collision Type | The type of collison to sample.*See [Collision Types](#collision-types)*. | Collision Details | Additional properties are available based on the selected `Collision Type`. | Ignore Self | Ignore the Actor owning the outer PCG graph. | Ignored Actor Selector | In-depth actor filtering.*Uses native PCG' actor filter. See Unreal documentation.*| ## Collision Types ### Channel |**Extra properties**||**Channel**|| Collision Channel | Project-specific. Selects a single collision channel to test against. |**Object Type**|| Collision Object Type | Same as Collision Channel, but work with a **flag**, allowing for a combination of types to test against. |**Profile**|| Collision Profile Name | Name of the collision profile to test against. | > Important note: under the hood this find the closest point on the closest collider -- this feature **is only supported for simple collider and won't work on complex ones**. {: .error } --- # Inputs ## In Points that will sample the environment for collision. Each point position in world space will be used as a center for a spherical query of the surrounding collisons. --- # Outputs ## Out Same as input, with additional metadata. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-nearest-surface.html",
    "relUrl": "/doc-sampling/sampling-nearest-surface.html"
  },"158": {
    "doc": "Sample Overlap Stats",
    "title": "Sample Overlap Stats",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-overlap-stats.html",
    "relUrl": "/doc-sampling/sampling-overlap-stats.html"
  },"159": {
    "doc": "Guided Trace",
    "title": "Guided Trace",
    "content": "{% include header_card_node %} # Properties > Each output property is written individually for each point. {: .comment } | Property | Description |:-------------|:------------------|**Settings**|| Direction | Select which property or attribute should be used as direction for the line trace. | Max Distance | Maximum trace distance. | Local Max Distance | If enabled, will use a local property or attribute as `Max Distance`. |**Outputs**|| **Success** Attribute Name | Writes a boolean attribute to each point specifying whether the sampling has been successful (`true`) or not (`false`).*Sampling is considered unsuccessful if there was no point within the specified range.* | **Location** Attribute Name | Writes the sampled location, as an `FVector`. | **Look at** Attribute Name | Writes the direction from the point to the sampled location, as an `FVector`. | **Normal** Attribute Name | Writes the normal of the surface at the sampled, as an `FVector`. | **Distance** Attribute Name | Writes the distance between the point and the sampled location, as a `double`. |**Collision Settings**|| Max Distance | The maximum distance to search for a collision, from the point location in world space.*In other words, the radius of the query sphere.* | Collision Type | The type of collison to sample.*See [Collision Types](#collision-types)*. | Collision Details | Additional properties are available based on the selected `Collision Type`. | Ignore Self | Ignore the Actor owning the outer PCG graph. | Ignored Actor Selector | In-depth actor filtering.*Uses native PCG' actor filter. See Unreal documentation.*| ## Collision Types ### Channel |**Extra properties**||:-------------|:------------------|**Channel**|| Collision Channel | Project-specific. Selects a single collision channel to test against. |**Object Type**|| Collision Object Type | Same as Collision Channel, but work with a **flag**, allowing for a combination of types to test against. |**Profile**|| Collision Profile Name | Name of the collision profile to test against. | --- # Inputs ## In Points that will sample the environment for collision. Each point position in world space will be used as a center for a spherical query of the surrounding collisons. --- # Outputs ## Out Same as input, with additional metadata. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-sampling/sampling-surface-guided.html",
    "relUrl": "/doc-sampling/sampling-surface-guided.html"
  },"160": {
    "doc": "A* Star",
    "title": "A* Star",
    "content": "{% include header_card_node %} [A* on Wikipedia](https://en.wikipedia.org/wiki/A*_search_algorithm) {: .fs-5 .fw-400 } {% include img a='details/modules/search-astar.png' %} > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/search/search-astar.html",
    "relUrl": "/doc-pathfinding/search/search-astar.html"
  },"161": {
    "doc": "Dijkstra",
    "title": "Dijkstra",
    "content": "{% include header_card_node %} [Dijkstra on Wikipedia](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) {: .fs-5 .fw-400 } {% include img a='details/modules/search-Dijkstra.png' %} > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-pathfinding/search/search-djikstra.html",
    "relUrl": "/doc-pathfinding/search/search-djikstra.html"
  },"162": {
    "doc": "settings-blending",
    "title": "settings-blending",
    "content": "--- ## Blending Settings > WIP {: .warning-hl } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-blending-reduced.html",
    "relUrl": "/settings/settings-blending-reduced.html"
  },"163": {
    "doc": "settings-blending",
    "title": "settings-blending",
    "content": "--- ## Blending Settings > WIP {: .warning-hl } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-blending.html",
    "relUrl": "/settings/settings-blending.html"
  },"164": {
    "doc": "settings-cluster-output",
    "title": "settings-cluster-output",
    "content": "--- ## Cluster Output Settings *See {% include lk id='Working with Clusters' a='#graph-output-settings-' %}.* | Property | Description |:-------------|:------------------| Edge Position | If enabled, edge point' position will be the result of that value used as a lerp between its start and end `Vtx` point. |: **Pruning** :|| Min Vtx Count | If enabled, only ouputs clusters that have at least the specified number of `Vtx` points. | Max Vtx Count | If enabled, only ouputs clusters that have at most the specified number of `Vtx` points. | Min Edge Count | If enabled, only ouputs clusters that have at least the specified number of `Edge` points. | Max Edge Count | If enabled, only ouputs clusters that have at most the specified number of `Edge` points. | Refresh Edge Seed | If enabled, `Edge` points gets a fresh seed. | Build and Cache Cluster | If enabled, pre-build and cache cluster along with the point data.**This has a slight memory cost associated to it, but can offer tremendous performance improvement.***If disabled, cluster processors that comes down the line have to rebuild clusters from point data, which is very costly as they are also tested for errors and possible disconnections in the process.* | Expand Clusters | If enabled, also build & cache another layer of cache data.**This can have a significant memory cost, as well as a minimal performance overhead, but can greatly improve certain specific operations down the line.** | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-cluster-output.html",
    "relUrl": "/settings/settings-cluster-output.html"
  },"165": {
    "doc": "settings-col-asset",
    "title": "settings-col-asset",
    "content": "--- ### Common properties #### Common properties are properties shared amonst all asset collection' entries {: .no_toc } | Property | Description |:-------------|:------------------|: **Sub Collection** :|| Sub Collection | If `Is Sub Collection` is enabled, lets you pick an **Asset Collection** that will work like a list of alternative choices for this entry. | Is Sub Collection | Whether this entry is a sub-collection or not.Enabling this option will reveal the **Asset Collection** picker. |: **Settings** :|| Weight | The weight of this entry, relative to the others in the list.Higher weights means higher chance of being picked, if the context is using weighted random selection. | Category | A category associated with this entry. *Think of it as a unique tag.* | > An entry `Weight` is not only used for Weighted Random selection, but is also used to sort entries in certain cases; among which `Indexed Weight` (Ascending/Descending) distribution mode of the {% include lk id='Asset Staging' %} node. {: .infos-hl } --- ### Variations Optionally, you may enter a few random ranges for staging nodes to use, should you want to. *This can come in handy if you want to have high-level, per-asset variations.* |: **Positions** :| *Additive* | Offset Min | Minimum offset range. | Offset Max | Maximum offset range. | Absolute offset | Whether the offset should be applied in world space, or \"local\" to the point' transform. |: **Rotation** :| *Additive* | Rotation Min | Minimum rotation offset range. | Rotation Max | Maximum rotation offset range. |: **Scale** :| *Multiplicative* | Scale Min | Minimum scale multiplier range. | Scale Max | Maximum scale multiplier range. | Uniform Scale | Whether the random scale multiplier should be applied per-component or uniformly (*in which case it uses `X` for all components*). | > Note that variations are **never** applied by default by any nodes, and are considered an advanced tweak. {: .comment } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-assets/asset-collections/settings-col-asset.html",
    "relUrl": "/doc-assets/asset-collections/settings-col-asset.html"
  },"166": {
    "doc": "settings-edge-types",
    "title": "settings-edge-types",
    "content": "## Edge Types Settings The Edge Types Settings allows you to choose which type or *quality* of edges you want to work with. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-edge-types.html",
    "relUrl": "/settings/settings-edge-types.html"
  },"167": {
    "doc": "settings-extra-weight",
    "title": "settings-extra-weight",
    "content": "|**Extra Weighting**||Weight up Visited| If enabled, points and edges will accumulate additional weight are paths are found.This allows you to make \"already in use\" points & edges either more or less desirable for the next internal execution. |Visited Points Weight Factor| The weight to add to points that have been visited. This is a multiplier of the Heuristic' Modifiers `Reference Weight`.*The weight is added each time a point is used.*|Visited Edges Weight Factor| The weight to add to edges that have been visited. This is a multiplier of the Heuristic' Modifiers `Reference Weight`.*The weight is added each time an edge is used.*| > **Important note on weighting up visited `Vtx` and `Edges`:** > - The weight is only computed for the pathfinding node and isn't carried over or cached. > - Enabling this feature breaks parallelism. Task are still ran asynchronously, but each path must wait for the previous one to be computed. Impact is usually negligible, but if you have *lots* of paths, it may take noticeably more time to process. ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-extra-weight.html",
    "relUrl": "/settings/settings-extra-weight.html"
  },"168": {
    "doc": "settings-index-safety",
    "title": "settings-index-safety",
    "content": "## Index Safety The index safety property controls how invalid indices are handled. | Safety method | Description |:-------------|:------------------| Ignore | Invalid indices will be ignored and won't be processed further. | Tile | Index is tiled (*wrapped around*) the context' valid min/max range.| Clamp | Index is clamped between the context' valid min/max range.| > Tiling index means that for a range of `[0..10]`, a value of `11` will be sanitized to `1` and a value of `-1` sanitized to `9`. {: .warning-hl } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-index-safety.html",
    "relUrl": "/settings/settings-index-safety.html"
  },"169": {
    "doc": "settings-blending",
    "title": "settings-blending",
    "content": "--- ## Influence Settings | Property | Description |:-------------|:------------------|**Settings**|| Influence | Interpolate between the original position and the final, relaxed position.- `1.0` means fully relaxed- `0.0` means the original position is preserved. | **Local Influence** | When enabled, this allows you to use a per-point influence value.*This is especially useful for \"pinning\" specific points.*| Progressive Influence | When enabled, `Influence` is **applied between each iteration**, instead of once after all iterations have been processed.*This is more expensive but yield more good looking results, especially with non-uniform local influence.*| >Note that while the default `Influence` is clamped, the local influence **is purposefully not clamped**, allowing for undershooting or overshooting the influence' interpolation between the relaxed and original position. Use carefully. {: .comment } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-influence.html",
    "relUrl": "/settings/settings-influence.html"
  },"170": {
    "doc": "settings-weighting",
    "title": "settings-weighting",
    "content": "--- ## Performance Settings |**Performance Settings**||Do Async Processing| Checked by default, you can toggle it off to force synchronous/unparallelized execution of the code. *It's usually a bad idea performance-wise.* > Note that synchronous execution still processes data in *chunks*, it just does it with guaranteed order, as opposed to parallel processing. |Chunk Size| The chunk size represents the number of point/operations a node will process in a single parallel batch. There is no ideal value: too small and you loose the gain of parallelization, too high and you're just hogging thread ressources. **Ultimately, it depends on your specific setup.**A value of `-1` fallbacks to that specific' node default value under the hood, which is usually a generic sweet spot; ranging from 64 to 4096 depending on the node.|Cache Result| Under the hood, all PCG node come with the ability to cache their result; but the system is designed so it's a compile-time choice, not an editor-time one **(at least in 5.3)**. I exposed the ability to cache on-demand at the price of some harmless asserts, because once you're done iterating on certain settings, it's worth caching the results.|Flatten Output| When enabled, all of the node output attributes will be flattened; primarily meaning that their metadata (attributes) are not inheriting parents, and the node can be safely saved to a data asset. *It's a rather costly operation, so make sure you need it, and for the sake of your RAM, don't enable it otherwise.* | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-performance.html",
    "relUrl": "/settings/settings-performance.html"
  },"171": {
    "doc": "settings-projection",
    "title": "settings-projection",
    "content": "--- ## Projection Settings The projection settings control how the point position is translated to a 2D space before the graph is computed; *and how this projection will translate back to the original space, if relevant.* | Property | Description |:-------------|:------------------| Projection Normal | Normal vector of the plane used for projection.By default, the projection plan normal is `Up`; so the graph is computed over the `X Y` plane. | Local Projection Normal | If enabled, uses a per-point projection vector.| > Local projection normal is very powerful but can also be very clunky to use -- **it's very easy to end up with singularities that will prevent the graph from being properly computed.** {: .warning-hl } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-projection.html",
    "relUrl": "/settings/settings-projection.html"
  },"172": {
    "doc": "settings-statistics",
    "title": "settings-statistics",
    "content": "| **Statistics** ||---| ![wip](https://img.shields.io/badge/WIP-c8860e) | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-statistics.html",
    "relUrl": "/settings/settings-statistics.html"
  },"173": {
    "doc": "settings-weighting",
    "title": "settings-weighting",
    "content": "## Weighting There is two weighting method available. `Full Range` and `Effective Range`. Each method outputs a `[0..1]` value that will be used to sample the `Weight Over Distance` curve. **However, there is a critical nuance between the two:** - `Full Range` is a simple normalization, each target distance is divided by the longest one. *As such, it's very unlikely the curve will get sampled close to `x=0`.* - `Effective Range` **remaps** each target distance using the shortest & longest distance as min/max. *As such, the shortest sampled distance will sample the curve at `x=0`, and the longest at `x=1`.* > Important note: when using the `Within range` sample method, some outputs will use the final weighted position/transforms for their calculations; although mathematically correct, **this may yield unusuable/innacurate results**. {: .error } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/settings/settings-weighting.html",
    "relUrl": "/settings/settings-weighting.html"
  },"174": {
    "doc": "Moving Average",
    "title": "Moving Average",
    "content": "{% include header_card_node %} {% include img a='docs/smooth/moving.png' %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Window Size | The number of leading & trailing points to sample.*The larger the window, the more uniform the result.* | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-smooth/smoothing-moving-average.html",
    "relUrl": "/doc-paths/paths-smooth/smoothing-moving-average.html"
  },"175": {
    "doc": "Radius",
    "title": "Radius",
    "content": "{% include header_card_node %} > Note that because of how the maths works for this module, it can be used with any input data: **whether the points are ordered as `paths` or not doesn't matter.** {: .infos-hl } {% include img a='docs/smooth/radius.png' %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| Blend Radius | Radius within which neighbor points will be sampled. | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-smooth/smoothing-radius.html",
    "relUrl": "/doc-paths/paths-smooth/smoothing-radius.html"
  },"176": {
    "doc": "üùò Sort Rule",
    "title": "üùò Sort Rule",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-misc/sort-points/sort-rule.html",
    "relUrl": "/doc-misc/sort-points/sort-rule.html"
  },"177": {
    "doc": "Auto Tangents",
    "title": "Auto Tangents",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| TBD | See{% include lk id='Tangents' a='#common-properties' %} *(Common properties)* | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-write-tangents/tangent-auto.html",
    "relUrl": "/doc-paths/paths-write-tangents/tangent-auto.html"
  },"178": {
    "doc": "Custom Tangents",
    "title": "Custom Tangents",
    "content": "{% include header_card_node %} # Properties | Property | Description |:-------------|:------------------|**Settings**|| TBD | See{% include lk id='Tangents' a='#common-properties' %} *(Common properties)* | ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-paths/paths-write-tangents/tangent-custom.html",
    "relUrl": "/doc-paths/paths-write-tangents/tangent-custom.html"
  },"179": {
    "doc": "üùä Best Match",
    "title": "üùä Best Match",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-write-vtx-properties/vtx-extra-best-match.html",
    "relUrl": "/doc-clusters/edges-write-vtx-properties/vtx-extra-best-match.html"
  },"180": {
    "doc": "üùä Special Edges",
    "title": "üùä Special Edges",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-write-vtx-properties/vtx-extra-special-edges.html",
    "relUrl": "/doc-clusters/edges-write-vtx-properties/vtx-extra-special-edges.html"
  },"181": {
    "doc": "üùä Special Neighbors",
    "title": "üùä Special Neighbors",
    "content": "{% include header_card_node %} # Properties > DOC TDB {: .warning } ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-clusters/edges-write-vtx-properties/vtx-extra-special-neighbors.html",
    "relUrl": "/doc-clusters/edges-write-vtx-properties/vtx-extra-special-neighbors.html"
  },"182": {
    "doc": "Working with Clusters",
    "title": "Working with Clusters",
    "content": "{% include header_card %} One of the main focus of PCGEx is working with Clusters : vtx & edge-based \"graph\" structures. They're akin to a mesh without faces: a bunch of vertices connected by a bunch of edges. {: .fs-5 .fw-400 } {% include imgc a='docs/vtx-edge-cluster.png' %} PCGEx leverage PCG' point data as data holders in order to enable easy tweaking and manipulation of edge/vertice data using existing vanilla nodes. In short, **a graph is represented by at least two separate set of points: the first, `Vtx` represent individual vertices; others, `Edges`, represent interconnected clusters.** `Edges` points stores the indices of their `start` and `end` point in the matching `Vtx` group. {: .fs-5 .fw-400 } >Because of that approach, nodes that work with graph require `Vtx` and `Edges` as separate inputs. Data Tags are used to mark which edges match which vertices, so you will see additional tags appear on your data, formatted as `PCGEx/Cluster::UID`. >**Rule of thumb** : If you manually alter *(as in add or remove points)* the content of a `Vtx` or `Edges` created by a PCGEx Node, make sure to use the {% include lk id='Sanitize Clusters' %} node before using them as inputs for other PCGEx nodes. {: .infos-hl } #### Checklist {: .no_toc } - TOC {:toc} --- ## Vtx A `Vtx` has one important piece of data written on it, and their position in space is relied upon for edge metrics -- `Vtx` being edges' start and end points. ### Cached Index The `PCGEx/CachedIndex` attribute hold the index of the `Vtx` when it was written into a graph. This is the index `PCGEx/EdgeStart` and `PCGEx/EdgeEnd` refers to on the `Edges` points. It is primarily useful to know whether the vtx structure has been altered or not, and ensure the graph is safe to use to avoid exceptions. ### Cached Edge Num The `PCGEx/CachedEdgeNum` attribute hold the number of edges connected to that `Vtx` when it was written into a graph. It is solely used for validation purposes when rebuilding a cluster to process it. >Note that this attribute can be reliably fetched to know how many unique edges are connected to a `Vtx` ;) --- ## Edges >**Rule of thumb** : The only information that matter on `Edges` for clusters is their `start` and `end` attribute. Their position in space is ignored so feel free to use those points if they can be relevant to you. {: .infos-hl } `Edges` have a single important piece of data written on them, and everything else is pretty much ignored by PCGEx -- meaning you can use the set of point *almost* as you see fit. ### Edge Endpoints The `PCGEx/Endpoints` attribute hold the *cached index* of its start `Vtx` when it was written into a cluster. --- ## Clusters In PCGEx terms, a cluster is \"a set of `Vtx` and `Edges` that are interconnected in a finite way\" -- in other words, **there is a guaranteed way inside a cluster that a path can be found between any `Vtx` to any other `Vtx` when passing through `Edges`.** A graph usually has a single set of vertices, but will output as many edge datasets as there are *clusters*. These will be then rebuilt inside the nodes to be processed. {% include imgc a='docs/vtx-edge-cluster-tag.png' %} >If you're unhappy with how clusters have been split in your graph, {% include lk id='Bridge Clusters' %} is here to save your day! {: .infos } --- ## Graph Output Settings üìå {% include imgc a='docs/graph-output-settings.png' %} This is a setting block you will see in a form or another on nodes that output sanitized clusters. They expose controls/filters over the `Vtx/Edges` output of the node to make sure the output is **sanitized, i.e, that it can be safely traversed by pathfinding search algorithms.** See the {% include lk id='Sanitize Clusters' %} node for more infos, as it encapsulate the sanitization behavior embedded in many other nodes. > If you want more fleshed out controls over `Edges` data & positioning, check out {% include lk id='Write Extras' %} Node! {: .infos } --- # Important Notes >Altering `PCGEx/CachedIndex`, `PCGEx/CachedEdgeNum`, `PCGEx/EdgeStart` or `PCGEx/EdgeEnd` voids the guarantee that PCGEx nodes will work as expected. {: .warning } >The `UID` used for the tagging is **NOT** deterministic, and will change *at each execution* of the graph, and for *each node*. It is used under the hood only, and should not be edited, nor relied upon for any kind of tag-related operations. For the same reason, if you create custom tags starting with `PCGEx/Cluster::`, it will break existing vtx/edge associations. >**Because of the reliance on the tagging system, if you edit `Vtx` and `Edges` before using them with a PCGEx node, make sure tags are preserved.** ",
    "url": "https://nebukam.github.io/PCGExtendedToolkit/doc-general/working-with-graphs.html",
    "relUrl": "/doc-general/working-with-graphs.html"
  }
}
